{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different make sequence function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "robot_dof = 7\n",
    "\n",
    "# Function to generate sequence names\n",
    "def generate_sequence(base_name, indices):\n",
    "    return [f'{base_name}{i}' for i in indices]\n",
    "\n",
    "# Automate the sequence generation using the function\n",
    "indices = range(robot_dof)  # Since the indices go from 0 to robot_dof\n",
    "\n",
    "# Create sequences for tau, tau_d, tau_ext, q, q_d, dq, dq_d, e, de, and etau\n",
    "tau = generate_sequence('tau_J', indices)\n",
    "tau_d = generate_sequence('tau_J_d', indices)\n",
    "tau_ext = generate_sequence('tau_ext', indices)\n",
    "\n",
    "q = generate_sequence('q', indices)\n",
    "q_d = generate_sequence('q_d', indices)\n",
    "\n",
    "dq = generate_sequence('dq', indices)\n",
    "dq_d = generate_sequence('dq_d', indices)\n",
    "\n",
    "e = generate_sequence('e', indices)\n",
    "de = generate_sequence('de', indices)\n",
    "etau = generate_sequence('etau_J', indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset, train_split_rate = 0.75):\n",
    "    msk = np.random.rand(len(dataset)) < train_split_rate\n",
    "    train = dataset.loc[msk, :]\n",
    "    test = dataset.loc[~msk, :]\n",
    "    return train, test\n",
    "\n",
    "def make_sequence(df, selected_features,seq_num, deltaMin, gap):\n",
    "    contact_indexs_ = df.loc[df.label.diff()>0.05,:].index\n",
    "    contact_indexs2 = df.loc[df.label.diff()<-0.05,:].index\n",
    "    contact_indexs = [idx for idx, idx2 in zip(contact_indexs_, contact_indexs2) if idx2 - idx >= seq_num]\n",
    "\n",
    "    dataset_df = pd.DataFrame()\n",
    "    for contact_index in contact_indexs:\n",
    "        window_right_edge = contact_index\n",
    "        end_point = contact_index + seq_num \n",
    "        for step in range(window_right_edge , end_point, gap):\n",
    "            label = df.label[step-1]\n",
    "            window = df[selected_features][step-seq_num:step]\n",
    "            df_dummy=pd.DataFrame(np.insert(window.values.flatten(), 0, label).reshape(1,-1))\n",
    "            dataset_df = pd.concat([dataset_df,df_dummy],ignore_index=True)\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rzma/myProjects/contact_localization_dataset/dataset/extracted_data/configuration5/\n",
      "/home/rzma/myProjects/contact_localization_dataset/dataset/extracted_data/configuration1/\n",
      "/home/rzma/myProjects/contact_localization_dataset/dataset/extracted_data/configuration4/\n",
      "/home/rzma/myProjects/contact_localization_dataset/dataset/extracted_data/configuration2/\n",
      "/home/rzma/myProjects/contact_localization_dataset/dataset/extracted_data/configuration6/\n",
      "/home/rzma/myProjects/contact_localization_dataset/dataset/extracted_data/in_motion/\n",
      "/home/rzma/myProjects/contact_localization_dataset/dataset/extracted_data/configuration3/\n",
      "/home/rzma/myProjects/contact_localization_dataset/dataset/extracted_data/configuration7/\n",
      "/home/rzma/myProjects/contact_localization_dataset/dataset/extracted_data/configuration8/\n",
      "0 (6415, 197)\n"
     ]
    }
   ],
   "source": [
    "main_path = os.getcwd().replace('AIModels','')\n",
    "\n",
    "#save_path = main_path+'/dataset/test_dataset_target_robot/'\n",
    "#main_path = main_path + 'frankaRobot/DATA/dataset/target_robot/'\n",
    "\n",
    "save_path = main_path+'dataset/e_edot/localization_gap_10/'\n",
    "main_path = os.path.expanduser('~/myProjects/contact_localization_dataset/dataset/extracted_data/')\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "selected_features = e + de\n",
    "seq_num = 28\n",
    "gap = 10 # 25 ms\n",
    "\n",
    "columns = range(seq_num*len(selected_features)+1)\n",
    "train_split_rate = 0.75\n",
    "\n",
    "dict_label = {'a': 7, 'b':6, 'c':5, 'd':4, 'e':3, 'f':2, 'g':1}\n",
    "\n",
    "\n",
    "for deltaMin in [0]: #range(int(seq_num/2)):\n",
    "    df_master_train = pd.DataFrame(columns=columns)\n",
    "    df_master_test = pd.DataFrame(columns=columns)\n",
    "    for i in os.listdir(main_path):\n",
    "        if len(i.split('.'))==1:\n",
    "\n",
    "            df_conf_train = pd.DataFrame(columns=columns)\n",
    "            df_conf_test = pd.DataFrame(columns=columns)\n",
    "\n",
    "            submain_path = main_path+i+'/'\n",
    "            print(submain_path)\n",
    "            for tag_name in os.listdir(submain_path):\n",
    "                if len(tag_name.split('.'))==1:\n",
    "                    file_path = submain_path+tag_name+'/labeled_data.csv'\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    df.drop(columns='index', inplace=True)\n",
    "                    df = make_sequence(df, selected_features,seq_num, deltaMin, gap)\n",
    "                    #labeling data\n",
    "                    df[0] = df[0]*dict_label[tag_name[0]]\n",
    "                    #print(df.loc[:,0].min())\n",
    "                    train, test = split_data(df, train_split_rate)\n",
    "                    df_conf_train = df_conf_train.append(train, ignore_index=True)\n",
    "                    df_conf_test = df_conf_test.append(test, ignore_index=True)\n",
    "\n",
    "        df_master_train = df_master_train.append(df_conf_train, ignore_index=True)\n",
    "        df_master_test = df_master_test.append(df_conf_test, ignore_index=True)\n",
    "\n",
    "    df_master_train.to_pickle(save_path+str(deltaMin)+'dataset_train.pkl')\n",
    "    df_master_test.to_pickle(save_path+str(deltaMin)+'dataset_test.pkl')\n",
    "    print(deltaMin, df_master_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378, 197)\n"
     ]
    }
   ],
   "source": [
    "main_path = os.getcwd().replace('AIModels','')\n",
    "\n",
    "#save_path = main_path+'/dataset/test_dataset_target_robot/'\n",
    "#main_path = main_path + 'frankaRobot/DATA/dataset/target_robot/'\n",
    "\n",
    "save_path = main_path+'dataset/test_dataset_source_robot/'\n",
    "main_path = main_path + 'frankaRobot/DATA/dataset/source_robot/'\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "selected_features = e\n",
    "seq_num = 28\n",
    "gap = 5 # 25 ms\n",
    "\n",
    "columns = range(seq_num*len(selected_features)+1)\n",
    "\n",
    "df_master = pd.DataFrame(columns=columns)\n",
    "for i in os.listdir(main_path):\n",
    "    if len(i.split('.'))==1:\n",
    "        file_path = main_path+i+'/labeled_data.csv'\n",
    "        df = pd.read_csv(file_path)\n",
    "        df.drop(columns='index', inplace=True)\n",
    "        df = make_sequence(df, selected_features,seq_num, gap)\n",
    "        #labeling data\n",
    "        if 'link5' in i:\n",
    "            df[0] = df[0]*5\n",
    "        elif 'link6' in i:\n",
    "            df[0] = df[0]*6\n",
    "        elif 'f' in i:\n",
    "            df[0] = df[0]*2\n",
    "        elif 'e' in i:\n",
    "            df[0] = df[0]*3\n",
    "        #print(df.loc[:,0].min())\n",
    "        df_master = df_master.append(df, ignore_index=True)\n",
    "\n",
    "df_master.to_pickle(save_path+'dataset_test.pkl')\n",
    "print(df_master.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1950, 169)\n"
     ]
    }
   ],
   "source": [
    "robot_dof = 6\n",
    "main_path = os.getcwd().replace('AIModels','')\n",
    "\n",
    "\n",
    "save_path = main_path+'/dataset/test_dataset_target_robot_ur5/'\n",
    "main_path = main_path + '/urRobot/DATA/dataset/UR5/'\n",
    "'''\n",
    "save_path = main_path + '/dataset/test_dataset_target_robot_ur10/'\n",
    "main_path = main_path + '/urRobot/DATA/dataset/UR10/'\n",
    "'''\n",
    "# Function to generate sequence names\n",
    "def generate_sequence(base_name, indices):\n",
    "    return [f'{base_name}{i}' for i in indices]\n",
    "\n",
    "# Automate the sequence generation using the function\n",
    "indices = range(robot_dof)  # Since the indices go from 0 to robot_dof\n",
    "selected_features = generate_sequence('e', indices)\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "seq_num = 28\n",
    "gap = 5 # 25 ms\n",
    "\n",
    "columns = range(seq_num*len(selected_features)+1)\n",
    "\n",
    "df_master = pd.DataFrame(columns=columns)\n",
    "for i in os.listdir(main_path):\n",
    "    if len(i.split('.'))==1:\n",
    "        file_path = main_path+i+'/labeled_data.csv'\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = make_sequence(df, selected_features,seq_num, gap)\n",
    "        #labeling data\n",
    "        if 'link5' in i:\n",
    "            df[0] = df[0]*5\n",
    "        elif 'link6' in i:\n",
    "            df[0] = df[0]*6\n",
    "        elif 'link3' in i:\n",
    "            df[0] = df[0]*3\n",
    "        elif 'link4' in i:\n",
    "            df[0] = df[0]*4\n",
    "        #print(df.loc[:,0].min())\n",
    "        df_master = df_master.append(df, ignore_index=True)\n",
    "\n",
    "df_master.to_pickle(save_path+'dataset_test.pkl')\n",
    "print(df_master.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
