2025-01-29 16:46:32,829 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 80, gap = 3, --------------
2025-01-29 16:46:41,721 - INFO - Accuracy on the test data = [91.90123677253723]
2025-01-29 16:46:41,762 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 80, gap = 5, --------------
2025-01-29 16:46:49,070 - INFO - Accuracy on the test data = [91.90123677253723]
2025-01-29 16:46:49,118 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 100, gap = 3, --------------
2025-01-29 16:46:54,926 - INFO - Accuracy on the test data = [91.1166250705719]
2025-01-29 16:46:54,966 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 100, gap = 5, --------------
2025-01-29 16:47:00,833 - INFO - Accuracy on the test data = [91.86103940010071]
2025-01-29 16:47:00,881 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 80, gap = 3, --------------
2025-01-29 16:47:09,572 - INFO - Accuracy on the test data = [92.74073839187622]
2025-01-29 16:47:09,618 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 80, gap = 5, --------------
2025-01-29 16:47:16,312 - INFO - Accuracy on the test data = [89.53086137771606]
2025-01-29 16:47:16,361 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 100, gap = 3, --------------
2025-01-29 16:47:22,228 - INFO - Accuracy on the test data = [92.85359978675842]
2025-01-29 16:47:22,270 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 100, gap = 5, --------------
2025-01-29 16:47:27,570 - INFO - Accuracy on the test data = [87.94044852256775]


2025-01-29 17:38:09,659 - INFO - trained model on franka_mindlab/trained_models/contact_localization/62/, tested on franka_mindlab, with 7 links
2025-01-29 17:40:01,730 - INFO - numLayer1_hiddenSize64_seq_num80_gap3_accuracy91.90, total samples: 5403
2025-01-29 17:40:01,731 - INFO - 
 [[833  13  11  21  11   0   1]
 [188 476 321  48  15  13   0]
 [  7 102 806  10   0   0   0]
 [  0  17  98 543   0   4   0]
 [  0   0   0  10 538   6   0]
 [ 22   0  17  66   0 551  94]
 [  3   0   0  11   0 261 286]]
2025-01-29 17:40:01,738 - INFO - 
               precision    recall  f1-score   support

           1       0.79      0.94      0.86       890
           2       0.78      0.45      0.57      1061
           3       0.64      0.87      0.74       925
           4       0.77      0.82      0.79       662
           5       0.95      0.97      0.96       554
           6       0.66      0.73      0.70       750
           7       0.75      0.51      0.61       561

    accuracy                           0.75      5403
   macro avg       0.76      0.76      0.75      5403
weighted avg       0.76      0.75      0.74      5403

2025-01-29 17:40:01,743 - INFO - numLayer1_hiddenSize64_seq_num100_gap3_accuracy91.12, total samples: 5371
2025-01-29 17:40:01,743 - INFO - 
 [[806   0  42  33   0   0   0]
 [111 485 440  20   0   0   0]
 [  0  21 896   0   0   0   0]
 [  0  17  79 569   0   0   0]
 [  0   0   0   0 535  10   0]
 [  0   0  30  90   2 585  36]
 [  0   0   0   1   0 330 233]]
2025-01-29 17:40:01,750 - INFO - 
               precision    recall  f1-score   support

           1       0.88      0.91      0.90       881
           2       0.93      0.46      0.61      1056
           3       0.60      0.98      0.75       917
           4       0.80      0.86      0.83       665
           5       1.00      0.98      0.99       545
           6       0.63      0.79      0.70       743
           7       0.87      0.41      0.56       564

    accuracy                           0.77      5371
   macro avg       0.81      0.77      0.76      5371
weighted avg       0.81      0.77      0.75      5371

2025-01-29 17:40:01,755 - INFO - numLayer1_hiddenSize64_seq_num80_gap5_accuracy91.90, total samples: 5405
2025-01-29 17:40:01,755 - INFO - 
 [[833  17  30   0  11   0   0]
 [168 473 400  24   0   0   0]
 [ 20  12 879  12   0   0   0]
 [  0  16  72 523   0  28  22]
 [  8   0   0   0 544   2   0]
 [ 10  13  11  52   0 522 139]
 [  8   6   0  11   0 278 261]]
2025-01-29 17:40:01,762 - INFO - 
               precision    recall  f1-score   support

           1       0.80      0.93      0.86       891
           2       0.88      0.44      0.59      1065
           3       0.63      0.95      0.76       923
           4       0.84      0.79      0.82       661
           5       0.98      0.98      0.98       554
           6       0.63      0.70      0.66       747
           7       0.62      0.46      0.53       564

    accuracy                           0.75      5405
   macro avg       0.77      0.75      0.74      5405
weighted avg       0.77      0.75      0.73      5405

2025-01-29 17:40:01,766 - INFO - numLayer1_hiddenSize64_seq_num100_gap5_accuracy91.86, total samples: 5372
2025-01-29 17:40:01,767 - INFO - 
 [[823  12  46   0   0   0   0]
 [159 481 390  26   1   0   0]
 [  0  95 806  19   0   0   0]
 [  0  19 104 542   0   0   0]
 [  0   0   0   0 544   0   0]
 [  0  20  18  63   0 496 145]
 [ 25   0   0   1   0 224 313]]
2025-01-29 17:40:01,774 - INFO - 
               precision    recall  f1-score   support

           1       0.82      0.93      0.87       881
           2       0.77      0.46      0.57      1057
           3       0.59      0.88      0.71       920
           4       0.83      0.82      0.82       665
           5       1.00      1.00      1.00       544
           6       0.69      0.67      0.68       742
           7       0.68      0.56      0.61       563

    accuracy                           0.75      5372
   macro avg       0.77      0.76      0.75      5372
weighted avg       0.76      0.75      0.74      5372

2025-01-29 17:40:01,778 - INFO - numLayer1_hiddenSize128_seq_num80_gap3_accuracy92.74, total samples: 5394
2025-01-29 17:40:01,779 - INFO - 
 [[850   0   0  38   0   0   0]
 [211 527 264  44  20   0   0]
 [ 12 130 749  32   0   0   0]
 [  0  16  87 524  14   5  14]
 [  6   0   0   0 533   0  10]
 [ 19   0  20 100   0 423 185]
 [ 18   2   0   9   0 168 364]]
2025-01-29 17:40:01,786 - INFO - 
               precision    recall  f1-score   support

           1       0.76      0.96      0.85       888
           2       0.78      0.49      0.61      1066
           3       0.67      0.81      0.73       923
           4       0.70      0.79      0.74       660
           5       0.94      0.97      0.96       549
           6       0.71      0.57      0.63       747
           7       0.64      0.65      0.64       561

    accuracy                           0.74      5394
   macro avg       0.74      0.75      0.74      5394
weighted avg       0.74      0.74      0.73      5394

2025-01-29 17:40:01,791 - INFO - numLayer1_hiddenSize128_seq_num100_gap3_accuracy92.85, total samples: 5374
2025-01-29 17:40:01,791 - INFO - 
 [[843   0  37   0   0   0   0]
 [174 480 401   4   0   0   0]
 [ 16  17 880   0   0   0   8]
 [  0  15 101 549   0   0   0]
 [  0   0   0   0 534   0  12]
 [  0   0  42   9   0 516 174]
 [  5   0   0   9   0 213 335]]
2025-01-29 17:40:01,798 - INFO - 
               precision    recall  f1-score   support

           1       0.81      0.96      0.88       880
           2       0.94      0.45      0.61      1059
           3       0.60      0.96      0.74       921
           4       0.96      0.83      0.89       665
           5       1.00      0.98      0.99       546
           6       0.71      0.70      0.70       741
           7       0.63      0.60      0.61       562

    accuracy                           0.77      5374
   macro avg       0.81      0.78      0.77      5374
weighted avg       0.81      0.77      0.76      5374

2025-01-29 17:40:01,803 - INFO - numLayer1_hiddenSize128_seq_num80_gap5_accuracy89.53, total samples: 5400
2025-01-29 17:40:01,803 - INFO - 
 [[787  34  56   3   9   0   0]
 [112 490 382  61  11   7   0]
 [ 10  41 859   7   0   7   0]
 [  0  12 112 508  14   1  17]
 [  2   0   0   9 543   0   0]
 [ 16   0  25  58   0 547 100]
 [ 12   0   0   9   0 208 331]]
2025-01-29 17:40:01,810 - INFO - 
               precision    recall  f1-score   support

           1       0.84      0.89      0.86       889
           2       0.85      0.46      0.60      1063
           3       0.60      0.93      0.73       924
           4       0.78      0.77      0.77       664
           5       0.94      0.98      0.96       554
           6       0.71      0.73      0.72       746
           7       0.74      0.59      0.66       560

    accuracy                           0.75      5400
   macro avg       0.78      0.76      0.76      5400
weighted avg       0.77      0.75      0.75      5400

2025-01-29 17:40:01,814 - INFO - numLayer1_hiddenSize128_seq_num100_gap5_accuracy87.94, total samples: 5371
2025-01-29 17:40:01,815 - INFO - 
 [[744   8 122   6   0   0   0]
 [ 88 445 431  73   0  19   0]
 [ 12  41 840   6   0   0  19]
 [  0  17  79 568   0   1   0]
 [  0   0   0   9 535   0   0]
 [ 12   0  19  61   0 526 124]
 [ 30   0   0   6   0 231 299]]
2025-01-29 17:40:01,822 - INFO - 
               precision    recall  f1-score   support

           1       0.84      0.85      0.84       880
           2       0.87      0.42      0.57      1056
           3       0.56      0.92      0.70       918
           4       0.78      0.85      0.81       665
           5       1.00      0.98      0.99       544
           6       0.68      0.71      0.69       742
           7       0.68      0.53      0.59       566

    accuracy                           0.74      5371
   macro avg       0.77      0.75      0.74      5371
weighted avg       0.77      0.74      0.73      5371

------------------------------------------------------------------------------------------------------------------------------------------------
2025-01-29 17:42:03,949 - INFO - trained model on franka_main/trained_models/contact_localization/62/, tested on franka_mindlab, with 7 links
2025-01-29 17:43:55,060 - INFO - numLayer1_hiddenSize64_seq_num80_gap3_accuracy91.68, total samples: 5390
2025-01-29 17:43:55,061 - INFO - 
 [[ 96 352 322  50  46  10  13]
 [  0 562 220 167  51  51  11]
 [  0 360 437  88   0  34   0]
 [  0  35  59 160 218 172  19]
 [  0   0   0   0 385 155  14]
 [  0  31   0  23  24 402 264]
 [  0   0   0   0  12 150 397]]
2025-01-29 17:43:55,067 - INFO - 
               precision    recall  f1-score   support

           1       1.00      0.11      0.19       889
           2       0.42      0.53      0.47      1062
           3       0.42      0.48      0.45       919
           4       0.33      0.24      0.28       663
           5       0.52      0.69      0.60       554
           6       0.41      0.54      0.47       744
           7       0.55      0.71      0.62       559

    accuracy                           0.45      5390
   macro avg       0.52      0.47      0.44      5390
weighted avg       0.53      0.45      0.43      5390

2025-01-29 17:43:55,073 - INFO - numLayer1_hiddenSize64_seq_num100_gap3_accuracy80.91, total samples: 5371
2025-01-29 17:43:55,073 - INFO - 
 [[108 350 336  66  16   0   0]
 [  0 485 367 125  60  19   0]
 [  0 223 558  51  45  43   0]
 [  0   0  57  97 156 353   0]
 [  0   0   0   0 340 203   4]
 [  0   0  30  27   0 614  72]
 [  0   0   0   0  18 188 360]]
2025-01-29 17:43:55,080 - INFO - 
               precision    recall  f1-score   support

           1       1.00      0.12      0.22       876
           2       0.46      0.46      0.46      1056
           3       0.41      0.61      0.49       920
           4       0.27      0.15      0.19       663
           5       0.54      0.62      0.58       547
           6       0.43      0.83      0.57       743
           7       0.83      0.64      0.72       566

    accuracy                           0.48      5371
   macro avg       0.56      0.49      0.46      5371
weighted avg       0.56      0.48      0.45      5371

2025-01-29 17:43:55,084 - INFO - numLayer1_hiddenSize64_seq_num80_gap5_accuracy91.13, total samples: 5401
2025-01-29 17:43:55,085 - INFO - 
 [[101 472 126  23  72  45  48]
 [  0 602 158  94  94 105   7]
 [  0 264 469  33  55 100   0]
 [  0   9  90 117 181 248  18]
 [  0   0   0   0 362 165  28]
 [  0  19   9  18  24 564 116]
 [  0   6   0   0   0 156 403]]
2025-01-29 17:43:55,092 - INFO - 
               precision    recall  f1-score   support

           1       1.00      0.11      0.20       887
           2       0.44      0.57      0.50      1060
           3       0.55      0.51      0.53       921
           4       0.41      0.18      0.25       663
           5       0.46      0.65      0.54       555
           6       0.41      0.75      0.53       750
           7       0.65      0.71      0.68       565

    accuracy                           0.48      5401
   macro avg       0.56      0.50      0.46      5401
weighted avg       0.57      0.48      0.45      5401

2025-01-29 17:43:55,097 - INFO - numLayer1_hiddenSize64_seq_num100_gap5_accuracy91.85, total samples: 5375
2025-01-29 17:43:55,097 - INFO - 
 [[  0 395 363  87  27   9   0]
 [  0 372 362 267  18  40   0]
 [  0 130 615  98  19  53   0]
 [  0   0  38 112  70 442   0]
 [  0   0   0   0 307 227  13]
 [  0   0  19  30  10 636  49]
 [  0   0   0   0  20 222 325]]
2025-01-29 17:43:55,104 - INFO - 
               precision    recall  f1-score   support

           1       0.00      0.00      0.00       881
           2       0.41      0.35      0.38      1059
           3       0.44      0.67      0.53       915
           4       0.19      0.17      0.18       662
           5       0.65      0.56      0.60       547
           6       0.39      0.85      0.54       744
           7       0.84      0.57      0.68       567

    accuracy                           0.44      5375
   macro avg       0.42      0.45      0.42      5375
weighted avg       0.39      0.44      0.39      5375

2025-01-29 17:43:55,109 - INFO - numLayer1_hiddenSize128_seq_num80_gap3_accuracy91.60, total samples: 5408
2025-01-29 17:43:55,110 - INFO - 
 [[ 35 439 308  47   8  41  10]
 [  0 481 369 116  71  28   1]
 [  0 253 522  41  48  28  31]
 [  0  14  50  57 181 334  28]
 [  0   0   4   0 279 258  15]
 [  0  20  23   6   7 358 334]
 [  0   0   4   0   0 136 423]]
2025-01-29 17:43:55,116 - INFO - 
               precision    recall  f1-score   support

           1       1.00      0.04      0.08       888
           2       0.40      0.45      0.42      1066
           3       0.41      0.57      0.47       923
           4       0.21      0.09      0.12       664
           5       0.47      0.50      0.49       556
           6       0.30      0.48      0.37       748
           7       0.50      0.75      0.60       563

    accuracy                           0.40      5408
   macro avg       0.47      0.41      0.36      5408
weighted avg       0.48      0.40      0.36      5408

2025-01-29 17:43:55,121 - INFO - numLayer1_hiddenSize128_seq_num100_gap3_accuracy91.61, total samples: 5369
2025-01-29 17:43:55,122 - INFO - 
 [[  0 510 336  29   4   0   0]
 [  0 395 485 161  16   0   0]
 [  0 144 621  49  88  16   0]
 [  0   0  36 141 337 151   0]
 [  0   0   0   0 388 157   0]
 [  0   0  19  30  22 601  71]
 [  0   0   0   0   2 190 370]]
2025-01-29 17:43:55,129 - INFO - 
               precision    recall  f1-score   support

           1       0.00      0.00      0.00       879
           2       0.38      0.37      0.38      1057
           3       0.41      0.68      0.51       918
           4       0.34      0.21      0.26       665
           5       0.45      0.71      0.55       545
           6       0.54      0.81      0.65       743
           7       0.84      0.66      0.74       562

    accuracy                           0.47      5369
   macro avg       0.42      0.49      0.44      5369
weighted avg       0.40      0.47      0.42      5369

2025-01-29 17:43:55,133 - INFO - numLayer1_hiddenSize128_seq_num80_gap5_accuracy91.52, total samples: 5397
2025-01-29 17:43:55,134 - INFO - 
 [[ 31 402 343  55  49   9   0]
 [  0 280 397 217 131  37   0]
 [  0 155 543  29 150  43   0]
 [  0   5  80 109  85 376   8]
 [  0   0   0   0 396 158   0]
 [  0   4  10  25   7 453 251]
 [  0   1   0   0   0 121 437]]
2025-01-29 17:43:55,141 - INFO - 
               precision    recall  f1-score   support

           1       1.00      0.03      0.07       889
           2       0.33      0.26      0.29      1062
           3       0.40      0.59      0.47       920
           4       0.25      0.16      0.20       663
           5       0.48      0.71      0.58       554
           6       0.38      0.60      0.47       750
           7       0.63      0.78      0.70       559

    accuracy                           0.42      5397
   macro avg       0.50      0.45      0.40      5397
weighted avg       0.50      0.42      0.37      5397

2025-01-29 17:43:55,145 - INFO - numLayer1_hiddenSize128_seq_num100_gap5_accuracy91.61, total samples: 5366
2025-01-29 17:43:55,146 - INFO - 
 [[119 571 113  40  17  20   0]
 [  0 553 254 187  44  17   0]
 [  0 259 489  91  39  39   0]
 [  0   7  10 124 222 299   0]
 [  0   0   0   0 177 366   2]
 [  0   6   0  54   0 509 173]
 [  0   0   0   0  11 234 320]]
2025-01-29 17:43:55,153 - INFO - 
               precision    recall  f1-score   support

           1       1.00      0.14      0.24       880
           2       0.40      0.52      0.45      1055
           3       0.56      0.53      0.55       917
           4       0.25      0.19      0.21       662
           5       0.35      0.32      0.34       545
           6       0.34      0.69      0.46       742
           7       0.65      0.57      0.60       565

    accuracy                           0.43      5366
   macro avg       0.51      0.42      0.41      5366
weighted avg       0.52      0.43      0.41      5366
------------------------------------------------------------------------------------------------------------------------------------------
lr = 0.0005

2025-01-29 18:06:25,941 - INFO - fine-tuning franka_main/trained_models/contact_localization/62/ on franka_mindlab with 7 links
2025-01-29 18:06:26,030 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 80, gap = 3, --------------
2025-01-29 18:06:31,277 - INFO - Accuracy on the test data = [91.11111164093018]
2025-01-29 18:06:31,334 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 100, gap = 3, --------------
2025-01-29 18:06:37,051 - INFO - Accuracy on the test data = [93.15136671066284]
2025-01-29 18:06:37,299 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 80, gap = 5, --------------
2025-01-29 18:06:42,774 - INFO - Accuracy on the test data = [90.17283916473389]
2025-01-29 18:06:42,828 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 100, gap = 5, --------------
2025-01-29 18:06:47,923 - INFO - Accuracy on the test data = [93.20099353790283]
2025-01-29 18:06:48,011 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 80, gap = 3, --------------
2025-01-29 18:06:53,256 - INFO - Accuracy on the test data = [93.03703904151917]
2025-01-29 18:06:53,316 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 100, gap = 3, --------------
2025-01-29 18:06:57,744 - INFO - Accuracy on the test data = [93.94540786743164]
2025-01-29 18:06:57,814 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 80, gap = 5, --------------
2025-01-29 18:07:02,282 - INFO - Accuracy on the test data = [92.04938411712646]
2025-01-29 18:07:02,333 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 100, gap = 5, --------------
2025-01-29 18:07:06,752 - INFO - Accuracy on the test data = [92.00992584228516]
2025-01-29 18:07:11,047 - INFO - Fine-tuned source model with franka_mindlab, tested on franka_mindlab, with 7 links
2025-01-29 18:09:03,550 - INFO - numLayer1_hiddenSize64_seq_num80_gap3_accuracy91.11, total samples: 5406
2025-01-29 18:09:03,551 - INFO - 
 [[817   1  53  20   0   0   0]
 [122 426 486   0   0  27   0]
 [  1 114 804   0   0   0   0]
 [  0  15  98 503  49   0   0]
 [  3   0   0   0 547   3   0]
 [  9  12   4  19  29 585  95]
 [  0   4   0   0   3 189 368]]
2025-01-29 18:09:03,558 - INFO - 
               precision    recall  f1-score   support

           1       0.86      0.92      0.89       891
           2       0.74      0.40      0.52      1061
           3       0.56      0.87      0.68       919
           4       0.93      0.76      0.83       665
           5       0.87      0.99      0.93       553
           6       0.73      0.78      0.75       753
           7       0.79      0.65      0.72       564

    accuracy                           0.75      5406
   macro avg       0.78      0.77      0.76      5406
weighted avg       0.77      0.75      0.74      5406

2025-01-29 18:09:03,563 - INFO - numLayer1_hiddenSize64_seq_num100_gap3_accuracy93.15, total samples: 5364
2025-01-29 18:09:03,563 - INFO - 
 [[849   9  19   0   0   0   0]
 [149 502 386  21   0   0   0]
 [  0  69 832  15   0   0   0]
 [  0  18  37 609   0   0   0]
 [  0   0   0   0 541   4   0]
 [  0   7  33  25   0 590  86]
 [  0   0   0   1   0  88 474]]
2025-01-29 18:09:03,570 - INFO - 
               precision    recall  f1-score   support

           1       0.85      0.97      0.91       877
           2       0.83      0.47      0.60      1058
           3       0.64      0.91      0.75       916
           4       0.91      0.92      0.91       664
           5       1.00      0.99      1.00       545
           6       0.87      0.80      0.83       741
           7       0.85      0.84      0.84       563

    accuracy                           0.82      5364
   macro avg       0.85      0.84      0.83      5364
weighted avg       0.83      0.82      0.81      5364

2025-01-29 18:09:03,575 - INFO - numLayer1_hiddenSize64_seq_num80_gap5_accuracy90.17, total samples: 5398
2025-01-29 18:09:03,576 - INFO - 
 [[798  60  30   0   0   0   0]
 [110 550 302  85   0  17   0]
 [  0 156 685  33  29  17   0]
 [  0  20  80 558   0   0   0]
 [  1   0   0   0 554   0   0]
 [  0  38  12   4   0 576 120]
 [  0   6   0   7   1 110 439]]
2025-01-29 18:09:03,582 - INFO - 
               precision    recall  f1-score   support

           1       0.88      0.90      0.89       888
           2       0.66      0.52      0.58      1064
           3       0.62      0.74      0.68       920
           4       0.81      0.85      0.83       658
           5       0.95      1.00      0.97       555
           6       0.80      0.77      0.78       750
           7       0.79      0.78      0.78       563

    accuracy                           0.77      5398
   macro avg       0.79      0.79      0.79      5398
weighted avg       0.77      0.77      0.77      5398

2025-01-29 18:09:03,587 - INFO - numLayer1_hiddenSize64_seq_num100_gap5_accuracy93.20, total samples: 5370
2025-01-29 18:09:03,588 - INFO - 
 [[850  23   9   0   0   0   0]
 [ 99 566 352  39   0   0   0]
 [  0 151 750   0   0  20   0]
 [  0  20  63 578   0   1   0]
 [  0   0   0   0 545   0   0]
 [  0   0  45  15   0 591  92]
 [  0   0   0   0   0 123 438]]
2025-01-29 18:09:03,594 - INFO - 
               precision    recall  f1-score   support

           1       0.90      0.96      0.93       882
           2       0.74      0.54      0.62      1056
           3       0.62      0.81      0.70       921
           4       0.91      0.87      0.89       662
           5       1.00      1.00      1.00       545
           6       0.80      0.80      0.80       743
           7       0.83      0.78      0.80       561

    accuracy                           0.80      5370
   macro avg       0.83      0.82      0.82      5370
weighted avg       0.81      0.80      0.80      5370

2025-01-29 18:09:03,599 - INFO - numLayer1_hiddenSize128_seq_num80_gap3_accuracy93.04, total samples: 5408
2025-01-29 18:09:03,600 - INFO - 
 [[855   4  16   0   0   3  11]
 [192 432 377  39   0  21   5]
 [ 14  55 828  16  12   0   0]
 [  0   0 118 521   3  19   0]
 [  1   0   0   0 552   0   0]
 [  0   6  27  26   0 535 157]
 [  0   6   0   0   0 142 415]]
2025-01-29 18:09:03,607 - INFO - 
               precision    recall  f1-score   support

           1       0.81      0.96      0.88       889
           2       0.86      0.41      0.55      1066
           3       0.61      0.90      0.72       925
           4       0.87      0.79      0.83       661
           5       0.97      1.00      0.99       553
           6       0.74      0.71      0.73       751
           7       0.71      0.74      0.72       563

    accuracy                           0.77      5408
   macro avg       0.79      0.79      0.77      5408
weighted avg       0.79      0.77      0.75      5408

2025-01-29 18:09:03,612 - INFO - numLayer1_hiddenSize128_seq_num100_gap3_accuracy93.95, total samples: 5371
2025-01-29 18:09:03,612 - INFO - 
 [[863   7   9   0   0   0   0]
 [139 511 377  27   0   4   0]
 [  0  68 825  13   0  14   0]
 [  0  13  63 586   0   0   0]
 [  0   0   0   0 546   0   0]
 [  4   0  31  20   6 569 113]
 [  0   0   0   5   0 131 427]]
2025-01-29 18:09:03,620 - INFO - 
               precision    recall  f1-score   support

           1       0.86      0.98      0.92       879
           2       0.85      0.48      0.62      1058
           3       0.63      0.90      0.74       920
           4       0.90      0.89      0.89       662
           5       0.99      1.00      0.99       546
           6       0.79      0.77      0.78       743
           7       0.79      0.76      0.77       563

    accuracy                           0.81      5371
   macro avg       0.83      0.82      0.82      5371
weighted avg       0.82      0.81      0.80      5371

2025-01-29 18:09:03,624 - INFO - numLayer1_hiddenSize128_seq_num80_gap5_accuracy92.05, total samples: 5407
2025-01-29 18:09:03,625 - INFO - 
 [[836   4  35   0   0   0  13]
 [153 460 338  92   1  18   0]
 [  7  95 762  19  40   0   0]
 [  0  20 107 500  16  21   0]
 [  7   0   0   0 543   6   0]
 [ 10  23  12  16   0 622  68]
 [  0   6   0   0   0  91 466]]
2025-01-29 18:09:03,632 - INFO - 
               precision    recall  f1-score   support

           1       0.83      0.94      0.88       888
           2       0.76      0.43      0.55      1062
           3       0.61      0.83      0.70       923
           4       0.80      0.75      0.77       664
           5       0.91      0.98      0.94       556
           6       0.82      0.83      0.82       751
           7       0.85      0.83      0.84       563

    accuracy                           0.77      5407
   macro avg       0.79      0.80      0.79      5407
weighted avg       0.78      0.77      0.77      5407

2025-01-29 18:09:03,637 - INFO - numLayer1_hiddenSize128_seq_num100_gap5_accuracy92.01, total samples: 5365
2025-01-29 18:09:03,638 - INFO - 
 [[826  45   9   0   0   0   0]
 [128 488 412  27   0   0   0]
 [  0  94 810  13   0   0   0]
 [  0  20  34 610   0   0   0]
 [  0   0   0   0 542   0   0]
 [  0   0  43  26   0 608  66]
 [  0   0   0   0   0 146 418]]
2025-01-29 18:09:03,644 - INFO - 
               precision    recall  f1-score   support

           1       0.87      0.94      0.90       880
           2       0.75      0.46      0.57      1055
           3       0.62      0.88      0.73       917
           4       0.90      0.92      0.91       664
           5       1.00      1.00      1.00       542
           6       0.81      0.82      0.81       743
           7       0.86      0.74      0.80       564

    accuracy                           0.80      5365
   macro avg       0.83      0.82      0.82      5365
weighted avg       0.81      0.80      0.80      5365
-------------------------------------------------------------------------------------------------------------------------
