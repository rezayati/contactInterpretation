2025-01-23 00:28:17,882 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 50, gap = 3, --------------
2025-01-23 00:28:33,395 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 50, gap = 3, --------------
2025-01-23 00:30:45,164 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 50, gap = 3, --------------
2025-01-23 00:32:13,492 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 50, gap = 3, --------------
2025-01-23 00:33:56,194 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 50, gap = 3, --------------
2025-01-23 00:37:05,142 - INFO - Accuracy on the test data = [80.28169274330139]
2025-01-23 00:37:05,655 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 50, gap = 5, --------------
2025-01-23 00:39:29,253 - INFO - Accuracy on the test data = [81.53364658355713]
2025-01-23 00:39:30,196 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 80, gap = 3, --------------
2025-01-23 00:40:47,691 - INFO - Accuracy on the test data = [86.38163208961487]
2025-01-23 00:40:48,266 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 80, gap = 5, --------------
2025-01-23 00:42:02,453 - INFO - Accuracy on the test data = [88.75693082809448]
2025-01-23 00:42:03,241 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 100, gap = 3, --------------
2025-01-23 00:43:05,617 - INFO - Accuracy on the test data = [91.30087494850159]
2025-01-23 00:43:06,242 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 100, gap = 5, --------------
2025-01-23 00:44:02,391 - INFO - Accuracy on the test data = [91.69992208480835]
2025-01-23 00:44:03,025 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 50, gap = 3, --------------
2025-01-23 00:46:35,496 - INFO - Accuracy on the test data = [80.28169274330139]
2025-01-23 00:46:36,019 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 50, gap = 5, --------------
2025-01-23 00:48:36,139 - INFO - Accuracy on the test data = [77.8560221195221]
2025-01-23 00:48:36,881 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 80, gap = 3, --------------
2025-01-23 00:49:55,277 - INFO - Accuracy on the test data = [90.73634147644043]
2025-01-23 00:49:55,883 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 80, gap = 5, --------------
2025-01-23 00:51:02,251 - INFO - Accuracy on the test data = [90.34045934677124]
2025-01-23 00:51:03,052 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 100, gap = 3, --------------
2025-01-23 00:52:05,746 - INFO - Accuracy on the test data = [91.6201114654541]
2025-01-23 00:52:06,380 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 100, gap = 5, --------------
2025-01-23 00:52:53,841 - INFO - Accuracy on the test data = [90.9018337726593]
2025-01-23 10:51:52,265 - INFO - numLayer1_hiddenSize64_seq_num50_gap3_accuracy80.28, total samples: 3946
2025-01-23 10:51:52,265 - INFO - 
 [[511  15   5   0  57  12   0]
 [  5 592  11  14   7   0   0]
 [  0  10 528   0   0   0   0]
 [  0   0  66 387  18   2   0]
 [ 18   0   0   0 628   0   0]
 [  0   0   0   0   2 603   0]
 [  0   0   0   0   0   0 455]]
2025-01-23 10:51:52,271 - INFO - 
               precision    recall  f1-score   support

           1       0.96      0.85      0.90       600
           2       0.96      0.94      0.95       629
           3       0.87      0.98      0.92       538
           4       0.97      0.82      0.89       473
           5       0.88      0.97      0.92       646
           6       0.98      1.00      0.99       605
           7       1.00      1.00      1.00       455

    accuracy                           0.94      3946
   macro avg       0.94      0.94      0.94      3946
weighted avg       0.94      0.94      0.94      3946

2025-01-23 10:51:52,276 - INFO - numLayer1_hiddenSize64_seq_num80_gap3_accuracy86.38, total samples: 3972
2025-01-23 10:51:52,277 - INFO - 
 [[586   0   0   0   5   1   0]
 [  0 634   6   0  12   0   0]
 [  0   0 532   0   0   0   0]
 [  0   0   0 478   3   0   0]
 [  0   0   0   0 657   0   0]
 [  0   0   0   0   1 596   0]
 [  0   0   0   0   0  22 439]]
2025-01-23 10:51:52,283 - INFO - 
               precision    recall  f1-score   support

           1       1.00      0.99      0.99       592
           2       1.00      0.97      0.99       652
           3       0.99      1.00      0.99       532
           4       1.00      0.99      1.00       481
           5       0.97      1.00      0.98       657
           6       0.96      1.00      0.98       597
           7       1.00      0.95      0.98       461

    accuracy                           0.99      3972
   macro avg       0.99      0.99      0.99      3972
weighted avg       0.99      0.99      0.99      3972

2025-01-23 10:51:52,287 - INFO - numLayer1_hiddenSize64_seq_num100_gap3_accuracy91.30, total samples: 3975
2025-01-23 10:51:52,288 - INFO - 
 [[584   1   0   0   0   0   0]
 [  0 647   0   0   0   0   0]
 [  0   0 519   0  14   0   0]
 [  0   0   0 467  16   0   0]
 [  0   0   0   0 635  21   0]
 [  0   0   0   0   0 601   0]
 [  0   0   0   0   0   0 470]]
2025-01-23 10:51:52,294 - INFO - 
               precision    recall  f1-score   support

           1       1.00      1.00      1.00       585
           2       1.00      1.00      1.00       647
           3       1.00      0.97      0.99       533
           4       1.00      0.97      0.98       483
           5       0.95      0.97      0.96       656
           6       0.97      1.00      0.98       601
           7       1.00      1.00      1.00       470

    accuracy                           0.99      3975
   macro avg       0.99      0.99      0.99      3975
weighted avg       0.99      0.99      0.99      3975

2025-01-23 10:51:52,299 - INFO - numLayer1_hiddenSize64_seq_num50_gap5_accuracy81.53, total samples: 3933
2025-01-23 10:51:52,299 - INFO - 
 [[537   1   0   1  49  15   0]
 [  1 621   2   1   0   3   0]
 [  0  21 469  31  12   0   5]
 [  0   2  46 393  22   2   0]
 [ 11   0   0   0 631   0   0]
 [  0   6   0   0   1 593   0]
 [  0   0   0   0   0   7 450]]
2025-01-23 10:51:52,306 - INFO - 
               precision    recall  f1-score   support

           1       0.98      0.89      0.93       603
           2       0.95      0.99      0.97       628
           3       0.91      0.87      0.89       538
           4       0.92      0.85      0.88       465
           5       0.88      0.98      0.93       642
           6       0.96      0.99      0.97       600
           7       0.99      0.98      0.99       457

    accuracy                           0.94      3933
   macro avg       0.94      0.94      0.94      3933
weighted avg       0.94      0.94      0.94      3933

2025-01-23 10:51:52,309 - INFO - numLayer1_hiddenSize64_seq_num80_gap5_accuracy88.76, total samples: 3969
2025-01-23 10:51:52,310 - INFO - 
 [[591   0   2   0   0   0   0]
 [  0 643   8   0   2   0   0]
 [  0  10 519   0   4   0   0]
 [  0   0   3 456  16   0   0]
 [  0   0   0   0 644  13   0]
 [  0   0   0   0  15 586   0]
 [  0   0   0   0   0   3 454]]
2025-01-23 10:51:52,316 - INFO - 
               precision    recall  f1-score   support

           1       1.00      1.00      1.00       593
           2       0.98      0.98      0.98       653
           3       0.98      0.97      0.97       533
           4       1.00      0.96      0.98       475
           5       0.95      0.98      0.96       657
           6       0.97      0.98      0.97       601
           7       1.00      0.99      1.00       457

    accuracy                           0.98      3969
   macro avg       0.98      0.98      0.98      3969
weighted avg       0.98      0.98      0.98      3969

2025-01-23 10:51:52,321 - INFO - numLayer1_hiddenSize64_seq_num100_gap5_accuracy91.70, total samples: 3978
2025-01-23 10:51:52,322 - INFO - 
 [[587   0   0   0   0   0   0]
 [  0 646   1   0   0   0   0]
 [  0   0 527   7   0   0   0]
 [  0   0   0 485   0   0   0]
 [  0   0   0   0 657   0   0]
 [  0   0   0  58  63 478   0]
 [  0   0   0   0   0   8 461]]
2025-01-23 10:51:52,329 - INFO - 
               precision    recall  f1-score   support

           1       1.00      1.00      1.00       587
           2       1.00      1.00      1.00       647
           3       1.00      0.99      0.99       534
           4       0.88      1.00      0.94       485
           5       0.91      1.00      0.95       657
           6       0.98      0.80      0.88       599
           7       1.00      0.98      0.99       469

    accuracy                           0.97      3978
   macro avg       0.97      0.97      0.97      3978
weighted avg       0.97      0.97      0.96      3978

2025-01-23 10:51:52,332 - INFO - numLayer1_hiddenSize128_seq_num50_gap3_accuracy80.28, total samples: 3937
2025-01-23 10:51:52,333 - INFO - 
 [[545   1   7   7  10  31   0]
 [  5 617   1   7   0   0   0]
 [  0  15 513   9   0   0   0]
 [  0   0  71 399   5   0   0]
 [ 14   0   7  21 599   2   0]
 [  0   0   0   0  16 585   0]
 [  0   0   0   0   0 130 320]]
2025-01-23 10:51:52,339 - INFO - 
               precision    recall  f1-score   support

           1       0.97      0.91      0.94       601
           2       0.97      0.98      0.98       630
           3       0.86      0.96      0.90       537
           4       0.90      0.84      0.87       475
           5       0.95      0.93      0.94       643
           6       0.78      0.97      0.87       601
           7       1.00      0.71      0.83       450

    accuracy                           0.91      3937
   macro avg       0.92      0.90      0.90      3937
weighted avg       0.92      0.91      0.91      3937

2025-01-23 10:51:52,343 - INFO - numLayer1_hiddenSize128_seq_num80_gap3_accuracy90.74, total samples: 3975
2025-01-23 10:51:52,343 - INFO - 
 [[584   0   7   0   3   0   0]
 [  0 639   8   0   4   0   0]
 [  0   0 528   0   6   0   0]
 [  0   0   0 459  25   0   0]
 [  0   0   0   0 613  43   0]
 [  0   0   0   0   4 590   0]
 [  0   0   0   0   0   2 460]]
2025-01-23 10:51:52,350 - INFO - 
               precision    recall  f1-score   support

           1       1.00      0.98      0.99       594
           2       1.00      0.98      0.99       651
           3       0.97      0.99      0.98       534
           4       1.00      0.95      0.97       484
           5       0.94      0.93      0.94       656
           6       0.93      0.99      0.96       594
           7       1.00      1.00      1.00       462

    accuracy                           0.97      3975
   macro avg       0.98      0.98      0.98      3975
weighted avg       0.98      0.97      0.97      3975

2025-01-23 10:51:52,353 - INFO - numLayer1_hiddenSize128_seq_num100_gap3_accuracy91.62, total samples: 3972
2025-01-23 10:51:52,354 - INFO - 
 [[587   0   0   0   0   0   0]
 [  0 646   0   0   0   0   0]
 [  0   0 534   0   0   0   0]
 [  0   0   0 472  13   0   0]
 [  0   0   0   0 652   3   0]
 [  0   0   0   1  20 574   0]
 [  0   0   0   0   0   0 470]]
2025-01-23 10:51:52,360 - INFO - 
               precision    recall  f1-score   support

           1       1.00      1.00      1.00       587
           2       1.00      1.00      1.00       646
           3       1.00      1.00      1.00       534
           4       1.00      0.97      0.99       485
           5       0.95      1.00      0.97       655
           6       0.99      0.96      0.98       595
           7       1.00      1.00      1.00       470

    accuracy                           0.99      3972
   macro avg       0.99      0.99      0.99      3972
weighted avg       0.99      0.99      0.99      3972

2025-01-23 10:51:52,366 - INFO - numLayer1_hiddenSize128_seq_num50_gap5_accuracy77.86, total samples: 3930
2025-01-23 10:51:52,366 - INFO - 
 [[514  20   0   2  45  17   0]
 [  0 612   5   0  13   0   0]
 [  0   7 512  17   0   0   0]
 [  0   0  44 401  22   0   0]
 [  6   0   0   0 641   0   0]
 [  0   0   0   0   0 599   0]
 [  0   0   0   0   0  11 442]]
2025-01-23 10:51:52,375 - INFO - 
               precision    recall  f1-score   support

           1       0.99      0.86      0.92       598
           2       0.96      0.97      0.96       630
           3       0.91      0.96      0.93       536
           4       0.95      0.86      0.90       467
           5       0.89      0.99      0.94       647
           6       0.96      1.00      0.98       599
           7       1.00      0.98      0.99       453

    accuracy                           0.95      3930
   macro avg       0.95      0.94      0.95      3930
weighted avg       0.95      0.95      0.95      3930

2025-01-23 10:51:52,382 - INFO - numLayer1_hiddenSize128_seq_num80_gap5_accuracy90.34, total samples: 3968
2025-01-23 10:51:52,383 - INFO - 
 [[594   0   0   0   0   0   0]
 [  0 597  43   0   7   0   0]
 [  0   0 533   0   0   0   0]
 [  0   0   0 464  16   0   0]
 [  0   0   0   0 644  13   0]
 [  0   0   0   6   8 586   0]
 [  0   0   0   0   0  10 447]]
2025-01-23 10:51:52,389 - INFO - 
               precision    recall  f1-score   support

           1       1.00      1.00      1.00       594
           2       1.00      0.92      0.96       647
           3       0.93      1.00      0.96       533
           4       0.99      0.97      0.98       480
           5       0.95      0.98      0.97       657
           6       0.96      0.98      0.97       600
           7       1.00      0.98      0.99       457

    accuracy                           0.97      3968
   macro avg       0.98      0.97      0.97      3968
weighted avg       0.98      0.97      0.97      3968

2025-01-23 10:51:52,394 - INFO - numLayer1_hiddenSize128_seq_num100_gap5_accuracy90.90, total samples: 3969
2025-01-23 10:51:52,394 - INFO - 
 [[584   0   2   0   0   0   0]
 [  0 620  25   0   0   0   0]
 [  0   0 534   0   0   0   0]
 [  0   0   0 485   0   0   0]
 [  0   0   0   0 655   0   0]
 [  0   0   0   5  91 498   0]
 [  0   0   0   0   0   1 469]]
2025-01-23 10:51:52,401 - INFO - 
               precision    recall  f1-score   support

           1       1.00      1.00      1.00       586
           2       1.00      0.96      0.98       645
           3       0.95      1.00      0.98       534
           4       0.99      1.00      0.99       485
           5       0.88      1.00      0.94       655
           6       1.00      0.84      0.91       594
           7       1.00      1.00      1.00       470

    accuracy                           0.97      3969
   macro avg       0.97      0.97      0.97      3969
weighted avg       0.97      0.97      0.97      3969

