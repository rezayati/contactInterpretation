2025-01-23 15:00:55,667 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 50, gap = 3, --------------
2025-01-23 15:01:23,749 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 50, gap = 3, --------------
2025-01-23 15:01:34,347 - INFO - Accuracy on the test data = [92.03051924705505]
2025-01-23 15:01:34,378 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 50, gap = 5, --------------
2025-01-23 15:01:42,188 - INFO - Accuracy on the test data = [91.26748442649841]
2025-01-23 15:01:42,227 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 80, gap = 3, --------------
2025-01-23 15:01:51,624 - INFO - Accuracy on the test data = [92.96075105667114]
2025-01-23 15:01:51,657 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 80, gap = 5, --------------
2025-01-23 15:01:57,409 - INFO - Accuracy on the test data = [91.93686246871948]
2025-01-23 15:01:57,450 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 100, gap = 3, --------------
2025-01-23 15:02:03,842 - INFO - Accuracy on the test data = [94.1302478313446]
2025-01-23 15:02:03,874 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 100, gap = 5, --------------
2025-01-23 15:02:09,529 - INFO - Accuracy on the test data = [92.33075976371765]
2025-01-23 15:02:09,563 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 50, gap = 3, --------------
2025-01-23 15:02:17,295 - INFO - Accuracy on the test data = [92.15769171714783]
2025-01-23 15:02:17,326 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 50, gap = 5, --------------
2025-01-23 15:02:22,942 - INFO - Accuracy on the test data = [92.53920912742615]
2025-01-23 15:02:22,979 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 80, gap = 3, --------------
2025-01-23 15:02:30,055 - INFO - Accuracy on the test data = [93.81399154663086]
2025-01-23 15:02:30,088 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 80, gap = 5, --------------
2025-01-23 15:02:35,904 - INFO - Accuracy on the test data = [91.68089032173157]
2025-01-23 15:02:35,947 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 100, gap = 3, --------------
2025-01-23 15:02:42,340 - INFO - Accuracy on the test data = [93.35904121398926]
2025-01-23 15:02:42,375 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 100, gap = 5, --------------
2025-01-23 15:02:47,597 - INFO - Accuracy on the test data = [91.4738655090332]
2025-01-23 15:07:55,127 - INFO - numLayer1_hiddenSize64_seq_num50_gap3_accuracy92.03, total samples: 4424
2025-01-23 15:07:55,128 - INFO - 
 [[503  56   3   0   0  16]
 [ 91 548  53  34   2   3]
 [ 72  26 730  86  53  34]
 [ 83  50 117 295  18  99]
 [  8   0  67  32 539  14]
 [ 87 192  26   2  10 475]]
2025-01-23 15:07:55,134 - INFO - 
               precision    recall  f1-score   support

           1       0.60      0.87      0.71       578
           2       0.63      0.75      0.68       731
           3       0.73      0.73      0.73      1001
           4       0.66      0.45      0.53       662
           5       0.87      0.82      0.84       660
           6       0.74      0.60      0.66       792

    accuracy                           0.70      4424
   macro avg       0.70      0.70      0.69      4424
weighted avg       0.71      0.70      0.69      4424

2025-01-23 15:07:55,139 - INFO - numLayer1_hiddenSize64_seq_num80_gap3_accuracy92.96, total samples: 4431
2025-01-23 15:07:55,139 - INFO - 
 [[519  43  15   0   0   0]
 [ 82 582  24  29   0   1]
 [ 20  66 805  76  24  22]
 [ 35  89 176 303   0  58]
 [  7   0 158  14 471  16]
 [103 148  41   0   9 495]]
2025-01-23 15:07:55,145 - INFO - 
               precision    recall  f1-score   support

           1       0.68      0.90      0.77       577
           2       0.63      0.81      0.71       718
           3       0.66      0.79      0.72      1013
           4       0.72      0.46      0.56       661
           5       0.93      0.71      0.81       666
           6       0.84      0.62      0.71       796

    accuracy                           0.72      4431
   macro avg       0.74      0.72      0.71      4431
weighted avg       0.74      0.72      0.71      4431

2025-01-23 15:07:55,149 - INFO - numLayer1_hiddenSize64_seq_num100_gap3_accuracy94.13, total samples: 4435
2025-01-23 15:07:55,150 - INFO - 
 [[552  16   1   6   0   0]
 [ 99 590   1   8   6   9]
 [ 58  30 850  38  32   7]
 [ 13  99 148 363  10  37]
 [  0   2 102  18 544   0]
 [109 116  57  36   1 477]]
2025-01-23 15:07:55,156 - INFO - 
               precision    recall  f1-score   support

           1       0.66      0.96      0.79       575
           2       0.69      0.83      0.75       713
           3       0.73      0.84      0.78      1015
           4       0.77      0.54      0.64       670
           5       0.92      0.82      0.86       666
           6       0.90      0.60      0.72       796

    accuracy                           0.76      4435
   macro avg       0.78      0.76      0.76      4435
weighted avg       0.78      0.76      0.76      4435

2025-01-23 15:07:55,160 - INFO - numLayer1_hiddenSize64_seq_num50_gap5_accuracy91.27, total samples: 4397
2025-01-23 15:07:55,160 - INFO - 
 [[485  55  15  22   0   0]
 [188 451  55  24  13   0]
 [114  72 607 179  23   0]
 [119  76 150 255  30  26]
 [ 15   5 112  93 413  18]
 [153 232 102  42  14 239]]
2025-01-23 15:07:55,166 - INFO - 
               precision    recall  f1-score   support

           1       0.45      0.84      0.59       577
           2       0.51      0.62      0.56       731
           3       0.58      0.61      0.60       995
           4       0.41      0.39      0.40       656
           5       0.84      0.63      0.72       656
           6       0.84      0.31      0.45       782

    accuracy                           0.56      4397
   macro avg       0.61      0.57      0.55      4397
weighted avg       0.61      0.56      0.55      4397

2025-01-23 15:07:55,171 - INFO - numLayer1_hiddenSize64_seq_num80_gap5_accuracy91.94, total samples: 4402
2025-01-23 15:07:55,171 - INFO - 
 [[494  31  12  13   0  22]
 [119 505  12   1  12  65]
 [ 59  45 673 108  61  56]
 [ 51  63 173 258  13 100]
 [ 10   9  69  63 504  12]
 [ 83  73  86  31   3 513]]
2025-01-23 15:07:55,177 - INFO - 
               precision    recall  f1-score   support

           1       0.61      0.86      0.71       572
           2       0.70      0.71      0.70       714
           3       0.66      0.67      0.66      1002
           4       0.54      0.39      0.46       658
           5       0.85      0.76      0.80       667
           6       0.67      0.65      0.66       789

    accuracy                           0.67      4402
   macro avg       0.67      0.67      0.67      4402
weighted avg       0.67      0.67      0.66      4402

2025-01-23 15:07:55,181 - INFO - numLayer1_hiddenSize64_seq_num100_gap5_accuracy92.33, total samples: 4422
2025-01-23 15:07:55,182 - INFO - 
 [[505  52  16   0   0   0]
 [131 558   0  20   0   1]
 [ 33  62 804  68  28  18]
 [ 35 114 150 225  40 100]
 [  0  15  87  35 507  29]
 [ 96  55  75  46  32 485]]
2025-01-23 15:07:55,188 - INFO - 
               precision    recall  f1-score   support

           1       0.63      0.88      0.74       573
           2       0.65      0.79      0.71       710
           3       0.71      0.79      0.75      1013
           4       0.57      0.34      0.43       664
           5       0.84      0.75      0.79       673
           6       0.77      0.61      0.68       789

    accuracy                           0.70      4422
   macro avg       0.69      0.69      0.68      4422
weighted avg       0.70      0.70      0.69      4422

2025-01-23 15:07:55,192 - INFO - numLayer1_hiddenSize128_seq_num50_gap3_accuracy92.16, total samples: 4424
2025-01-23 15:07:55,192 - INFO - 
 [[510  60   0   4   0   8]
 [ 88 491  56  41  35  17]
 [ 68  63 593 194  60  20]
 [ 39  61 159 304  30  65]
 [  0   0  32   0 633   3]
 [103 171   0  36  11 469]]
2025-01-23 15:07:55,198 - INFO - 
               precision    recall  f1-score   support

           1       0.63      0.88      0.73       582
           2       0.58      0.67      0.62       728
           3       0.71      0.59      0.65       998
           4       0.53      0.46      0.49       658
           5       0.82      0.95      0.88       668
           6       0.81      0.59      0.68       790

    accuracy                           0.68      4424
   macro avg       0.68      0.69      0.68      4424
weighted avg       0.68      0.68      0.67      4424

2025-01-23 15:07:55,203 - INFO - numLayer1_hiddenSize128_seq_num80_gap3_accuracy93.81, total samples: 4435
2025-01-23 15:07:55,203 - INFO - 
 [[536  31   7   0   0   2]
 [ 25 630  23  17   2  23]
 [ 42  52 805  36  49  27]
 [ 75  63  95 325  13  92]
 [  8   0  79   3 557  21]
 [ 86 119  12  30   0 550]]
2025-01-23 15:07:55,209 - INFO - 
               precision    recall  f1-score   support

           1       0.69      0.93      0.80       576
           2       0.70      0.88      0.78       720
           3       0.79      0.80      0.79      1011
           4       0.79      0.49      0.61       663
           5       0.90      0.83      0.86       668
           6       0.77      0.69      0.73       797

    accuracy                           0.77      4435
   macro avg       0.77      0.77      0.76      4435
weighted avg       0.78      0.77      0.76      4435

2025-01-23 15:07:55,213 - INFO - numLayer1_hiddenSize128_seq_num100_gap3_accuracy93.36, total samples: 4439
2025-01-23 15:07:55,214 - INFO - 
 [[530  46   0   0   0   0]
 [151 555   0   0   0   9]
 [ 55  45 760  92  62   0]
 [ 27  85  69 415   0  72]
 [  0   0  61   8 579  22]
 [ 90 179   0  15   4 508]]
2025-01-23 15:07:55,220 - INFO - 
               precision    recall  f1-score   support

           1       0.62      0.92      0.74       576
           2       0.61      0.78      0.68       715
           3       0.85      0.75      0.80      1014
           4       0.78      0.62      0.69       668
           5       0.90      0.86      0.88       670
           6       0.83      0.64      0.72       796

    accuracy                           0.75      4439
   macro avg       0.77      0.76      0.75      4439
weighted avg       0.78      0.75      0.76      4439

2025-01-23 15:07:55,224 - INFO - numLayer1_hiddenSize128_seq_num50_gap5_accuracy92.54, total samples: 4416
2025-01-23 15:07:55,224 - INFO - 
 [[513  47  12   0   0  10]
 [158 434  93   2  32   7]
 [149  48 652  91  20  36]
 [101  64 159 217  35  84]
 [ 44   0  69  46 476  27]
 [144 131  42  27  29 417]]
2025-01-23 15:07:55,230 - INFO - 
               precision    recall  f1-score   support

           1       0.46      0.88      0.61       582
           2       0.60      0.60      0.60       726
           3       0.63      0.65      0.64       996
           4       0.57      0.33      0.42       660
           5       0.80      0.72      0.76       662
           6       0.72      0.53      0.61       790

    accuracy                           0.61      4416
   macro avg       0.63      0.62      0.61      4416
weighted avg       0.64      0.61      0.61      4416

2025-01-23 15:07:55,234 - INFO - numLayer1_hiddenSize128_seq_num80_gap5_accuracy91.68, total samples: 4410
2025-01-23 15:07:55,235 - INFO - 
 [[487  48  20  13   0   7]
 [ 90 565  23  37   0   2]
 [ 62  45 733 108  24  35]
 [ 64  71 110 349   4  59]
 [ 18   4  74  15 554   0]
 [ 77 156  35  35  10 476]]
2025-01-23 15:07:55,241 - INFO - 
               precision    recall  f1-score   support

           1       0.61      0.85      0.71       575
           2       0.64      0.79      0.70       717
           3       0.74      0.73      0.73      1007
           4       0.63      0.53      0.57       657
           5       0.94      0.83      0.88       665
           6       0.82      0.60      0.70       789

    accuracy                           0.72      4410
   macro avg       0.73      0.72      0.72      4410
weighted avg       0.73      0.72      0.72      4410

2025-01-23 15:07:55,245 - INFO - numLayer1_hiddenSize128_seq_num100_gap5_accuracy91.47, total samples: 4421
2025-01-23 15:07:55,246 - INFO - 
 [[486  64  19   7   0   0]
 [124 553   1  29   0   3]
 [ 31  47 588 169 156  18]
 [ 30 109  62 357  19  86]
 [  0   0  36  16 601  19]
 [ 98 110  37  23  24 499]]
2025-01-23 15:07:55,252 - INFO - 
               precision    recall  f1-score   support

           1       0.63      0.84      0.72       576
           2       0.63      0.78      0.69       710
           3       0.79      0.58      0.67      1009
           4       0.59      0.54      0.56       663
           5       0.75      0.89      0.82       672
           6       0.80      0.63      0.70       791

    accuracy                           0.70      4421
   macro avg       0.70      0.71      0.70      4421
weighted avg       0.71      0.70      0.69      4421

2025-01-23 15:45:12,067 - INFO - trained model on franka_main, tested on ur5

---------------------------------------------------------------------------------------------------------------------------------
2025-01-23 15:57:19,734 - INFO - trained model on franka_main, tested on ur5
2025-01-23 16:00:42,072 - INFO - numLayer1_hiddenSize64_seq_num50_gap3_accuracy80.28, total samples: 4444
2025-01-23 16:00:42,073 - INFO - 
 [[ 55 164 114 157  68  22]
 [  9 192  79 208 184  62]
 [  0   7  53 728 142  71]
 [  2  55  86 427  47  51]
 [  0   0  21 493  74  83]
 [ 24 108  59 388 116  95]]
2025-01-23 16:00:42,080 - INFO - 
               precision    recall  f1-score   support

           1       0.61      0.09      0.16       580
           2       0.37      0.26      0.30       734
           3       0.13      0.05      0.08      1001
           4       0.18      0.64      0.28       668
           5       0.12      0.11      0.11       671
           6       0.25      0.12      0.16       790

    accuracy                           0.20      4444
   macro avg       0.27      0.21      0.18      4444
weighted avg       0.26      0.20      0.18      4444

2025-01-23 16:00:42,084 - INFO - numLayer1_hiddenSize64_seq_num80_gap3_accuracy86.38, total samples: 4435
2025-01-23 16:00:42,084 - INFO - 
 [[ 46 144 119  65 131  68]
 [ 21  79 113 208 152 147]
 [  1   0   9 627 246 125]
 [ 17  32  74 321  75 148]
 [  0  15   4 458 133  61]
 [  7  55  22 457 160  95]]
2025-01-23 16:00:42,090 - INFO - 
               precision    recall  f1-score   support

           1       0.50      0.08      0.14       573
           2       0.24      0.11      0.15       720
           3       0.03      0.01      0.01      1008
           4       0.15      0.48      0.23       667
           5       0.15      0.20      0.17       671
           6       0.15      0.12      0.13       796

    accuracy                           0.15      4435
   macro avg       0.20      0.17      0.14      4435
weighted avg       0.18      0.15      0.13      4435

2025-01-23 16:00:42,095 - INFO - numLayer1_hiddenSize64_seq_num100_gap3_accuracy91.30, total samples: 4431
2025-01-23 16:00:42,095 - INFO - 
 [[ 84 124  52 142  61 112]
 [ 30 137   9 318  97 119]
 [ 15   0  59 474 236 226]
 [  1  21  52 325 142 127]
 [  0   0   2 400  91 180]
 [  9  34  20 331 190 211]]
2025-01-23 16:00:42,101 - INFO - 
               precision    recall  f1-score   support

           1       0.60      0.15      0.24       575
           2       0.43      0.19      0.27       710
           3       0.30      0.06      0.10      1010
           4       0.16      0.49      0.24       668
           5       0.11      0.14      0.12       673
           6       0.22      0.27      0.24       795

    accuracy                           0.20      4431
   macro avg       0.31      0.21      0.20      4431
weighted avg       0.30      0.20      0.19      4431

2025-01-23 16:00:42,105 - INFO - numLayer1_hiddenSize64_seq_num50_gap5_accuracy81.53, total samples: 4433
2025-01-23 16:00:42,105 - INFO - 
 [[ 44 190 118 165  37  22]
 [ 10 243 119 166  92 102]
 [  0  67  79 656 137  63]
 [  0  38  70 426  65  70]
 [  0   7   0 527  65  68]
 [ 26 138  76 348  97 102]]
2025-01-23 16:00:42,111 - INFO - 
               precision    recall  f1-score   support

           1       0.55      0.08      0.13       576
           2       0.36      0.33      0.34       732
           3       0.17      0.08      0.11      1002
           4       0.19      0.64      0.29       669
           5       0.13      0.10      0.11       667
           6       0.24      0.13      0.17       787

    accuracy                           0.22      4433
   macro avg       0.27      0.23      0.19      4433
weighted avg       0.26      0.22      0.19      4433

2025-01-23 16:00:42,115 - INFO - numLayer1_hiddenSize64_seq_num80_gap5_accuracy88.76, total samples: 4420
2025-01-23 16:00:42,116 - INFO - 
 [[130 143 119  39 103  36]
 [ 21 244  72 182 166  37]
 [  0  42  23 448 275 217]
 [ 17  63 120 306  59  99]
 [  0   4  11 360 170 122]
 [  0 147  43 270 185 147]]
2025-01-23 16:00:42,122 - INFO - 
               precision    recall  f1-score   support

           1       0.77      0.23      0.35       570
           2       0.38      0.34      0.36       722
           3       0.06      0.02      0.03      1005
           4       0.19      0.46      0.27       664
           5       0.18      0.25      0.21       667
           6       0.22      0.19      0.20       792

    accuracy                           0.23      4420
   macro avg       0.30      0.25      0.24      4420
weighted avg       0.27      0.23      0.22      4420

2025-01-23 16:00:42,126 - INFO - numLayer1_hiddenSize64_seq_num100_gap5_accuracy91.70, total samples: 4418
2025-01-23 16:00:42,127 - INFO - 
 [[168  50 105  26  90 131]
 [ 38 187  17 266 161  44]
 [ 31  45 103 387 263 181]
 [ 35  38  74 316 114  89]
 [  0  10   0 326 203 130]
 [  8  97  24 314 130 217]]
2025-01-23 16:00:42,132 - INFO - 
               precision    recall  f1-score   support

           1       0.60      0.29      0.40       570
           2       0.44      0.26      0.33       713
           3       0.32      0.10      0.15      1010
           4       0.19      0.47      0.27       666
           5       0.21      0.30      0.25       669
           6       0.27      0.27      0.27       790

    accuracy                           0.27      4418
   macro avg       0.34      0.29      0.28      4418
weighted avg       0.33      0.27      0.27      4418

2025-01-23 16:00:42,138 - INFO - numLayer1_hiddenSize128_seq_num50_gap3_accuracy80.28, total samples: 4435
2025-01-23 16:00:42,139 - INFO - 
 [[ 62 133 177 130  54  18]
 [ 12 312 138 134 112  26]
 [  0  66 103 613 176  45]
 [ 21  76 144 314  87  25]
 [  0   0   9 560  59  42]
 [ 40 234 108 282  68  55]]
2025-01-23 16:00:42,148 - INFO - 
               precision    recall  f1-score   support

           1       0.46      0.11      0.17       574
           2       0.38      0.43      0.40       734
           3       0.15      0.10      0.12      1003
           4       0.15      0.47      0.23       667
           5       0.11      0.09      0.10       670
           6       0.26      0.07      0.11       787

    accuracy                           0.20      4435
   macro avg       0.25      0.21      0.19      4435
weighted avg       0.24      0.20      0.19      4435

2025-01-23 16:00:42,154 - INFO - numLayer1_hiddenSize128_seq_num80_gap3_accuracy90.74, total samples: 4436
2025-01-23 16:00:42,154 - INFO - 
 [[111  88 128 100  92  49]
 [ 13 181 129 117 178 105]
 [ 27  28  19 542 233 165]
 [ 21  23  71 362 128  60]
 [  0   0   0 460 103 105]
 [  0  57  65 342 249  85]]
2025-01-23 16:00:42,163 - INFO - 
               precision    recall  f1-score   support

           1       0.65      0.20      0.30       568
           2       0.48      0.25      0.33       723
           3       0.05      0.02      0.03      1014
           4       0.19      0.54      0.28       665
           5       0.10      0.15      0.12       668
           6       0.15      0.11      0.12       798

    accuracy                           0.19      4436
   macro avg       0.27      0.21      0.20      4436
weighted avg       0.24      0.19      0.18      4436

2025-01-23 16:00:42,169 - INFO - numLayer1_hiddenSize128_seq_num100_gap3_accuracy91.62, total samples: 4427
2025-01-23 16:00:42,170 - INFO - 
 [[130  37  52 154 121  77]
 [ 50 128   7 327 121  79]
 [ 18  21  62 479 316 116]
 [  7  78  17 369 100  95]
 [  0   0   0 442 111 115]
 [  0  50  22 362 157 207]]
2025-01-23 16:00:42,176 - INFO - 
               precision    recall  f1-score   support

           1       0.63      0.23      0.34       571
           2       0.41      0.18      0.25       712
           3       0.39      0.06      0.11      1012
           4       0.17      0.55      0.26       666
           5       0.12      0.17      0.14       668
           6       0.30      0.26      0.28       798

    accuracy                           0.23      4427
   macro avg       0.34      0.24      0.23      4427
weighted avg       0.33      0.23      0.22      4427

2025-01-23 16:00:42,181 - INFO - numLayer1_hiddenSize128_seq_num50_gap5_accuracy77.86, total samples: 4432
2025-01-23 16:00:42,181 - INFO - 
 [[101 129 150 133  62   3]
 [ 17 252 106 171 140  47]
 [  0  55  88 609 181  65]
 [  4  55 186 322  76  23]
 [  0   2   6 487 113  60]
 [  0 183  86 343 125  52]]
2025-01-23 16:00:42,190 - INFO - 
               precision    recall  f1-score   support

           1       0.83      0.17      0.29       578
           2       0.37      0.34      0.36       733
           3       0.14      0.09      0.11       998
           4       0.16      0.48      0.24       666
           5       0.16      0.17      0.17       668
           6       0.21      0.07      0.10       789

    accuracy                           0.21      4432
   macro avg       0.31      0.22      0.21      4432
weighted avg       0.29      0.21      0.20      4432

2025-01-23 16:00:42,195 - INFO - numLayer1_hiddenSize128_seq_num80_gap5_accuracy90.34, total samples: 4415
2025-01-23 16:00:42,196 - INFO - 
 [[ 49 168 154  48 115  36]
 [  0 323  85 140 130  41]
 [  0  47  38 586 122 206]
 [  0  72  91 329 100  71]
 [  0   0   6 375 105 183]
 [  0 163  31 286 236  79]]
2025-01-23 16:00:42,202 - INFO - 
               precision    recall  f1-score   support

           1       1.00      0.09      0.16       570
           2       0.42      0.45      0.43       719
           3       0.09      0.04      0.05       999
           4       0.19      0.50      0.27       663
           5       0.13      0.16      0.14       669
           6       0.13      0.10      0.11       795

    accuracy                           0.21      4415
   macro avg       0.33      0.22      0.20      4415
weighted avg       0.29      0.21      0.19      4415

2025-01-23 16:00:42,206 - INFO - numLayer1_hiddenSize128_seq_num100_gap5_accuracy90.90, total samples: 4427
2025-01-23 16:00:42,207 - INFO - 
 [[ 96  67  82  55 160 110]
 [ 77 124  39 143 291  39]
 [ 11   8  80 400 376 133]
 [  0  71  69 183 154 192]
 [  0   0   0 337 153 181]
 [ 18 136  23 189 233 197]]
2025-01-23 16:00:42,213 - INFO - 
               precision    recall  f1-score   support

           1       0.48      0.17      0.25       570
           2       0.31      0.17      0.22       713
           3       0.27      0.08      0.12      1008
           4       0.14      0.27      0.19       669
           5       0.11      0.23      0.15       671
           6       0.23      0.25      0.24       796

    accuracy                           0.19      4427
   macro avg       0.26      0.20      0.19      4427
weighted avg       0.25      0.19      0.19      4427
----------------------------------------------------------------------------------------------------------------------

2025-01-23 17:13:31,024 - INFO - fine-tuning on pickleDatasets_0_2ur5 with 6 links
2025-01-23 17:13:31,076 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 50, gap = 3, --------------
2025-01-23 17:13:39,053 - INFO - Accuracy on the test data = [90.75879454612732]
2025-01-23 17:13:39,096 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 80, gap = 3, --------------
2025-01-23 17:13:45,626 - INFO - Accuracy on the test data = [94.62457299232483]
2025-01-23 17:13:45,671 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 100, gap = 3, --------------
2025-01-23 17:13:51,567 - INFO - Accuracy on the test data = [92.33075976371765]
2025-01-23 17:13:51,605 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 50, gap = 5, --------------
2025-01-23 17:13:58,221 - INFO - Accuracy on the test data = [93.34463477134705]
2025-01-23 17:13:58,259 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 80, gap = 5, --------------
2025-01-23 17:14:04,535 - INFO - Accuracy on the test data = [93.21672320365906]
2025-01-23 17:14:04,577 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=64 seq_num = 100, gap = 5, --------------
2025-01-23 17:14:09,897 - INFO - Accuracy on the test data = [93.95886659622192]
2025-01-23 17:14:09,939 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 50, gap = 3, --------------
2025-01-23 17:14:17,152 - INFO - Accuracy on the test data = [91.52182936668396]
2025-01-23 17:14:17,198 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 80, gap = 3, --------------
2025-01-23 17:14:23,141 - INFO - Accuracy on the test data = [93.55801939964294]
2025-01-23 17:14:23,190 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 100, gap = 3, --------------
2025-01-23 17:14:29,212 - INFO - Accuracy on the test data = [91.5595531463623]
2025-01-23 17:14:29,251 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 50, gap = 5, --------------
2025-01-23 17:14:34,606 - INFO - Accuracy on the test data = [90.75879454612732]
2025-01-23 17:14:34,646 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 80, gap = 5, --------------
2025-01-23 17:14:39,913 - INFO - Accuracy on the test data = [92.1928346157074]
2025-01-23 17:14:39,955 - INFO - ------------  model_cnnLSTM , num_layers = 1, hidden_size=128 seq_num = 100, gap = 5, --------------
2025-01-23 17:14:45,165 - INFO - Accuracy on the test data = [91.98800325393677]
2025-01-23 17:15:05,597 - INFO - Fine-tuned source model with ur5, tested on ur5, with 6 links
2025-01-23 17:18:26,563 - INFO - numLayer1_hiddenSize64_seq_num50_gap3_accuracy90.76, total samples: 4457
2025-01-23 17:18:26,564 - INFO - 
 [[478  80  25   0   0   0]
 [ 69 527  42  52  34  12]
 [110  27 673 189   5   3]
 [ 11 109 150 345  38  10]
 [  9   0  59   0 576  28]
 [143 126  27  14   1 485]]
2025-01-23 17:18:26,571 - INFO - 
               precision    recall  f1-score   support

           1       0.58      0.82      0.68       583
           2       0.61      0.72      0.66       736
           3       0.69      0.67      0.68      1007
           4       0.57      0.52      0.55       663
           5       0.88      0.86      0.87       672
           6       0.90      0.61      0.73       796

    accuracy                           0.69      4457
   macro avg       0.71      0.70      0.69      4457
weighted avg       0.71      0.69      0.69      4457

2025-01-23 17:18:26,575 - INFO - numLayer1_hiddenSize64_seq_num80_gap3_accuracy94.62, total samples: 4454
2025-01-23 17:18:26,575 - INFO - 
 [[560  17   0   0   0   0]
 [ 59 613  11  26   9   7]
 [ 34  45 729 131  42  34]
 [ 21  97 183 314  32  20]
 [ 12   0  87   0 558  15]
 [ 68 146  23  25   0 536]]
2025-01-23 17:18:26,581 - INFO - 
               precision    recall  f1-score   support

           1       0.74      0.97      0.84       577
           2       0.67      0.85      0.75       725
           3       0.71      0.72      0.71      1015
           4       0.63      0.47      0.54       667
           5       0.87      0.83      0.85       672
           6       0.88      0.67      0.76       798

    accuracy                           0.74      4454
   macro avg       0.75      0.75      0.74      4454
weighted avg       0.75      0.74      0.74      4454

2025-01-23 17:18:26,586 - INFO - numLayer1_hiddenSize64_seq_num100_gap3_accuracy92.33, total samples: 4440
2025-01-23 17:18:26,586 - INFO - 
 [[503  72   0   0   0   0]
 [ 57 648   0   0   0   9]
 [ 39  66 779  41  70  20]
 [  2 155  84 355  26  46]
 [  0   0  60   8 573  31]
 [108 133  19  32  23 481]]
2025-01-23 17:18:26,592 - INFO - 
               precision    recall  f1-score   support

           1       0.71      0.87      0.78       575
           2       0.60      0.91      0.72       714
           3       0.83      0.77      0.80      1015
           4       0.81      0.53      0.64       668
           5       0.83      0.85      0.84       672
           6       0.82      0.60      0.70       796

    accuracy                           0.75      4440
   macro avg       0.77      0.76      0.75      4440
weighted avg       0.77      0.75      0.75      4440

2025-01-23 17:18:26,596 - INFO - numLayer1_hiddenSize64_seq_num50_gap5_accuracy93.34, total samples: 4435
2025-01-23 17:18:26,596 - INFO - 
 [[532  43   5   0   0   0]
 [ 84 572  42  37   1   1]
 [ 83  54 726 122  11   9]
 [ 41  95 165 334  11  13]
 [ 10   0  45  15 556  40]
 [116 202  42   2   0 426]]
2025-01-23 17:18:26,603 - INFO - 
               precision    recall  f1-score   support

           1       0.61      0.92      0.74       580
           2       0.59      0.78      0.67       737
           3       0.71      0.72      0.72      1005
           4       0.65      0.51      0.57       659
           5       0.96      0.83      0.89       666
           6       0.87      0.54      0.67       788

    accuracy                           0.71      4435
   macro avg       0.73      0.72      0.71      4435
weighted avg       0.74      0.71      0.71      4435

2025-01-23 17:18:26,607 - INFO - numLayer1_hiddenSize64_seq_num80_gap5_accuracy93.22, total samples: 4441
2025-01-23 17:18:26,607 - INFO - 
 [[527  22  26   0   0   0]
 [ 26 645   5  47   0   0]
 [ 35  38 753 107  36  44]
 [ 17 140 167 313   0  27]
 [ 24   2 108   0 529   5]
 [ 99 249  27  16   0 407]]
2025-01-23 17:18:26,613 - INFO - 
               precision    recall  f1-score   support

           1       0.72      0.92      0.81       575
           2       0.59      0.89      0.71       723
           3       0.69      0.74      0.72      1013
           4       0.65      0.47      0.55       664
           5       0.94      0.79      0.86       668
           6       0.84      0.51      0.64       798

    accuracy                           0.71      4441
   macro avg       0.74      0.72      0.71      4441
weighted avg       0.74      0.71      0.71      4441

2025-01-23 17:18:26,617 - INFO - numLayer1_hiddenSize64_seq_num100_gap5_accuracy93.96, total samples: 4442
2025-01-23 17:18:26,618 - INFO - 
 [[546  16   9   0   0   5]
 [ 38 634   0  20  11  10]
 [ 42  44 787  49  63  28]
 [ 11 124 113 379  11  30]
 [  0   0  88  10 566  10]
 [102 144  29  22   0 501]]
2025-01-23 17:18:26,624 - INFO - 
               precision    recall  f1-score   support

           1       0.74      0.95      0.83       576
           2       0.66      0.89      0.76       713
           3       0.77      0.78      0.77      1013
           4       0.79      0.57      0.66       668
           5       0.87      0.84      0.85       674
           6       0.86      0.63      0.73       798

    accuracy                           0.77      4442
   macro avg       0.78      0.77      0.77      4442
weighted avg       0.78      0.77      0.76      4442

2025-01-23 17:18:26,628 - INFO - numLayer1_hiddenSize128_seq_num50_gap3_accuracy91.52, total samples: 4460
2025-01-23 17:18:26,629 - INFO - 
 [[492  62  29   0   0   0]
 [ 49 530  48  62  39   9]
 [ 79  35 694 133  34  33]
 [ 30  81 164 325  41  27]
 [  0   0  25   9 625   8]
 [ 94 215  13   0  16 459]]
2025-01-23 17:18:26,635 - INFO - 
               precision    recall  f1-score   support

           1       0.66      0.84      0.74       583
           2       0.57      0.72      0.64       737
           3       0.71      0.69      0.70      1008
           4       0.61      0.49      0.54       668
           5       0.83      0.94      0.88       667
           6       0.86      0.58      0.69       797

    accuracy                           0.70      4460
   macro avg       0.71      0.71      0.70      4460
weighted avg       0.71      0.70      0.70      4460

2025-01-23 17:18:26,639 - INFO - numLayer1_hiddenSize128_seq_num80_gap3_accuracy93.56, total samples: 4442
2025-01-23 17:18:26,640 - INFO - 
 [[536  27  13   0   0   0]
 [ 70 619   2  11  19   0]
 [ 41  45 678  94 114  35]
 [ 28 106 122 385   0  26]
 [ 30   0  44  24 558  15]
 [107 188  24  37   0 444]]
2025-01-23 17:18:26,645 - INFO - 
               precision    recall  f1-score   support

           1       0.66      0.93      0.77       576
           2       0.63      0.86      0.73       721
           3       0.77      0.67      0.72      1007
           4       0.70      0.58      0.63       667
           5       0.81      0.83      0.82       671
           6       0.85      0.56      0.67       800

    accuracy                           0.72      4442
   macro avg       0.74      0.74      0.72      4442
weighted avg       0.74      0.72      0.72      4442

2025-01-23 17:18:26,649 - INFO - numLayer1_hiddenSize128_seq_num100_gap3_accuracy91.56, total samples: 4447
2025-01-23 17:18:26,650 - INFO - 
 [[490  56  30   0   0   0]
 [ 43 652   0   0   6  13]
 [ 33  57 794  13  94  24]
 [  4 147 122 321  26  48]
 [  0   0  65   9 567  32]
 [ 82 178  18  25   9 489]]
2025-01-23 17:18:26,656 - INFO - 
               precision    recall  f1-score   support

           1       0.75      0.85      0.80       576
           2       0.60      0.91      0.72       714
           3       0.77      0.78      0.78      1015
           4       0.87      0.48      0.62       668
           5       0.81      0.84      0.82       673
           6       0.81      0.61      0.70       801

    accuracy                           0.74      4447
   macro avg       0.77      0.75      0.74      4447
weighted avg       0.77      0.74      0.74      4447

2025-01-23 17:18:26,660 - INFO - numLayer1_hiddenSize128_seq_num50_gap5_accuracy90.76, total samples: 4434
2025-01-23 17:18:26,661 - INFO - 
 [[477  68  31   0   0   4]
 [ 76 536  51  45   1  22]
 [ 89  34 700 149  10  24]
 [ 24 118 171 307   2  37]
 [  5   0  19  27 605  10]
 [115 197  19   3   9 449]]
2025-01-23 17:18:26,667 - INFO - 
               precision    recall  f1-score   support

           1       0.61      0.82      0.70       580
           2       0.56      0.73      0.64       731
           3       0.71      0.70      0.70      1006
           4       0.58      0.47      0.52       659
           5       0.96      0.91      0.94       666
           6       0.82      0.57      0.67       792

    accuracy                           0.69      4434
   macro avg       0.71      0.70      0.69      4434
weighted avg       0.71      0.69      0.69      4434

2025-01-23 17:18:26,671 - INFO - numLayer1_hiddenSize128_seq_num80_gap5_accuracy92.19, total samples: 4442
2025-01-23 17:18:26,672 - INFO - 
 [[503  48  26   0   0   0]
 [ 75 596   6  29   0  17]
 [ 33  46 743  70  77  43]
 [ 34 132 118 330  18  30]
 [  1   0  35   0 596  36]
 [ 90 198  40   0   0 472]]
2025-01-23 17:18:26,677 - INFO - 
               precision    recall  f1-score   support

           1       0.68      0.87      0.77       577
           2       0.58      0.82      0.68       723
           3       0.77      0.73      0.75      1012
           4       0.77      0.50      0.60       662
           5       0.86      0.89      0.88       668
           6       0.79      0.59      0.68       800

    accuracy                           0.73      4442
   macro avg       0.74      0.74      0.73      4442
weighted avg       0.75      0.73      0.73      4442

2025-01-23 17:18:26,682 - INFO - numLayer1_hiddenSize128_seq_num100_gap5_accuracy91.99, total samples: 4443
2025-01-23 17:18:26,682 - INFO - 
 [[500  68   8   0   0   0]
 [ 33 667   0   0  15   0]
 [ 37  56 792  53  68   7]
 [  6 152 156 324   1  30]
 [  4   0  73  10 560  26]
 [ 89 237  21  35   0 415]]
2025-01-23 17:18:26,688 - INFO - 
               precision    recall  f1-score   support

           1       0.75      0.87      0.80       576
           2       0.57      0.93      0.70       715
           3       0.75      0.78      0.77      1013
           4       0.77      0.48      0.59       669
           5       0.87      0.83      0.85       673
           6       0.87      0.52      0.65       797

    accuracy                           0.73      4443
   macro avg       0.76      0.74      0.73      4443
weighted avg       0.76      0.73      0.73      4443

