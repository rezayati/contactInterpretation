{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy.linalg._umath_linalg' has no attribute '_ilp64'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m ConfusionMatrix\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m transforms\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m precision_score, recall_score, f1_score,  classification_report\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mload_dataset\u001b[39;00m \u001b[39mimport\u001b[39;00m create_tensor_dataset_without_torque\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/__init__.py:83\u001b[0m\n\u001b[1;32m     72\u001b[0m     sys\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39mPartial import of sklearn during the build process.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m     \u001b[39m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[39m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[39m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[39m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     84\u001b[0m         __check_build,  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     85\u001b[0m         _distributor_init,  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     )\n\u001b[1;32m     87\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m clone\n\u001b[1;32m     88\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_show_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/base.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _IS_32BIT\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_estimator_html_repr\u001b[39;00m \u001b[39mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_metadata_requests\u001b[39;00m \u001b[39mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcontextlib\u001b[39;00m \u001b[39mimport\u001b[39;00m contextmanager, suppress\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mitertools\u001b[39;00m \u001b[39mimport\u001b[39;00m compress, islice\n\u001b[0;32m---> 15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m issparse\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/scipy/sparse/__init__.py:294\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39m# Original code by Travis Oliphant.\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# Modified and extended by Ed Schofield, Robert Cimrman,\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m# Nathan Bell, and Jake Vanderplas.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_warnings\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_base\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    295\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_csr\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    296\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_csc\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/scipy/sparse/_base.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwarnings\u001b[39;00m \u001b[39mimport\u001b[39;00m warn\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_lib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_util\u001b[39;00m \u001b[39mimport\u001b[39;00m VisibleDeprecationWarning\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_sputils\u001b[39;00m \u001b[39mimport\u001b[39;00m (asmatrix, check_reshape_kwargs, check_shape,\n\u001b[1;32m      8\u001b[0m                        get_sum_dtype, isdense, isscalarlike,\n\u001b[1;32m      9\u001b[0m                        matrix, validateaxis,)\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_matrix\u001b[39;00m \u001b[39mimport\u001b[39;00m spmatrix\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/scipy/_lib/_util.py:18\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     Optional,\n\u001b[1;32m     12\u001b[0m     Union,\n\u001b[1;32m     13\u001b[0m     TYPE_CHECKING,\n\u001b[1;32m     14\u001b[0m     TypeVar,\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_lib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_array_api\u001b[39;00m \u001b[39mimport\u001b[39;00m array_namespace\n\u001b[1;32m     21\u001b[0m AxisError: \u001b[39mtype\u001b[39m[\u001b[39mException\u001b[39;00m]\n\u001b[1;32m     22\u001b[0m ComplexWarning: \u001b[39mtype\u001b[39m[\u001b[39mWarning\u001b[39;00m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/scipy/_lib/_array_api.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mimport\u001b[39;00m assert_\n\u001b[1;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_lib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marray_api_compat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marray_api_compat\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39marray_api_compat\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_lib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marray_api_compat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marray_api_compat\u001b[39;00m \u001b[39mimport\u001b[39;00m size\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/numpy/testing/__init__.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39munittest\u001b[39;00m \u001b[39mimport\u001b[39;00m TestCase\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _private\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (_assert_valid_refcount, _gen_alignment_data)\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_private\u001b[39;00m \u001b[39mimport\u001b[39;00m extbuild\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/numpy/testing/_private/utils.py:57\u001b[0m\n\u001b[1;32m     55\u001b[0m IS_PYSTON \u001b[39m=\u001b[39m \u001b[39mhasattr\u001b[39m(sys, \u001b[39m\"\u001b[39m\u001b[39mpyston_version_info\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m HAS_REFCOUNT \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(sys, \u001b[39m'\u001b[39m\u001b[39mgetrefcount\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m IS_PYSTON\n\u001b[0;32m---> 57\u001b[0m HAS_LAPACK64 \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49m_umath_linalg\u001b[39m.\u001b[39;49m_ilp64\n\u001b[1;32m     59\u001b[0m _OLD_PROMOTION \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m: np\u001b[39m.\u001b[39m_get_promotion_state() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlegacy\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     61\u001b[0m IS_MUSL \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy.linalg._umath_linalg' has no attribute '_ilp64'"
     ]
    }
   ],
   "source": [
    "# By Maryam Rezayati\n",
    "# Ref  for lstm: https://machinelearningmastery.com/lstm-for-time-series-prediction-in-pytorch/\n",
    "\n",
    "# this model should be trained in the same conda environment which robot will be runned\n",
    "# conda activate frankapyenv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,  classification_report\n",
    "from load_dataset import create_tensor_dataset_without_torque\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from main.py import get_output or\n",
    "def get_output(data_ds, model):\n",
    "    labels_pred = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(data_ds.data_target.shape[0]):\n",
    "            x , y = data_ds.__getitem__(i)\n",
    "            x = x[None, :]\n",
    "\n",
    "            x = model(x)\n",
    "            x = x.squeeze()\n",
    "            #labels_pred.append(torch.Tensor.cpu(x.detach()).numpy())\n",
    "            labels_pred.append(x.detach().numpy())\n",
    "    #convert list type to array\n",
    "    labels_pred = np.array(labels_pred)\n",
    "    labels_pred = labels_pred.argmax(axis=1)\n",
    "    labels_true = np.array(data_ds.data_target[:])\n",
    "    labels_true = labels_true.astype('int64')\n",
    "\n",
    "    return torch.tensor(labels_pred), torch.tensor(labels_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from main.py import Sequence or\n",
    "class Sequence(nn.Module):\n",
    "    def __init__(self, num_class = 5, network_type='main',num_features_lstm=4):\n",
    "        super(Sequence, self).__init__()\n",
    "        hidden_size = 50\n",
    "        self.lstm = nn.LSTM(input_size = num_features_lstm*28, hidden_size= hidden_size, num_layers= 1, batch_first = True)\n",
    "        self.network_type = network_type\n",
    "        if self.network_type == 'main':\n",
    "            self.linear = nn.Linear(hidden_size, num_class)    \n",
    "        else:\n",
    "            self.linear = nn.Linear(hidden_size*7, num_class)\n",
    "\n",
    "        #self.linear2 = nn.Linear(50, num_class)\n",
    "\n",
    "    def forward(self, input, future = 0):\n",
    "        x, _ = self.lstm(input)\n",
    "\n",
    "        if self.network_type == 'main':\n",
    "            x = x[:,-1,:]\n",
    "        else:\n",
    "            x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = self.linear(x)\n",
    "        #x = self.linear2(x)\n",
    "        #x = x[:,-1,:]\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_lstm_models(PATH:str, num_features_lstm=4):\n",
    "\n",
    "\tcheckpoint = torch.load(PATH)\n",
    "\n",
    "\tmodel = Sequence(num_class = checkpoint[\"num_classes\"], network_type = checkpoint[\"network_type\"], num_features_lstm = num_features_lstm)\n",
    "\tmodel.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "\tif checkpoint[\"collision\"]:\n",
    "\t\tlabels_map = { # , is for saving data\n",
    "\t\t\t\t\t0: ',Collaborative_Contact',\n",
    "\t\t\t\t\t1: ',Collision,'\n",
    "\t\t\t\t\t\t}\n",
    "\t\tprint('collision detection model is loaded!')\n",
    "\t\t\n",
    "\telif checkpoint[\"localization\"]:\n",
    "\t\tlabels_map = { # , is for saving data\n",
    "\t\t\t\t\t0: ',Link 5',\n",
    "\t\t\t\t\t1: ',Link 6,'\n",
    "\t\t\t\t\t\t}\n",
    "\t\tprint('localization model is loaded!')\n",
    "\t\n",
    "\telif checkpoint[\"num_classes\"] == 5:\n",
    "\t\tlabels_map = { # , is for saving data\n",
    "\t\t\t\t\t0: ',Noncontact,',\n",
    "\t\t\t\t\t1: ',Intentional_Link5,',\n",
    "\t\t\t\t\t2: ',Intentional_Link6,',\n",
    "\t\t\t\t\t3: ',Collision_Link5,',\n",
    "\t\t\t\t\t4: ',Collision_Link6,',\n",
    "\t\t\t\t\t\t}\n",
    "\t\tprint('5-classes model is loaded!')\n",
    "\n",
    "\telif checkpoint[\"num_classes\"] == 3: \n",
    "\t\tlabels_map = { # , is for saving data\n",
    "\t\t\t\t\t0: ',Noncontact,',\n",
    "\t\t\t\t\t1: ',Collaborative_Contact,',\n",
    "\t\t\t\t\t2: ',Collision,',\n",
    "\t\t\t\t} \n",
    "\t\tprint('collision detection with 3 classes model is loaded!')\n",
    "\n",
    "\telif checkpoint[\"num_classes\"] ==2:\n",
    "\t\tlabels_map = { # , is for saving data\n",
    "\t\t\t\t\t0: ',Noncontact,',\n",
    "\t\t\t\t\t1: ',Contact,',\n",
    "\t\t\t\t} \n",
    "\t\tprint('contact detection model is loaded!')\n",
    "\t\t\n",
    "\treturn model.eval(), labels_map\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modular LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run and test single modles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contact detection model is loaded!\n",
      "collision detection model is loaded!\n",
      "localization model is loaded!\n",
      "contact detection on the test set: \n",
      " tensor([[360,   0],\n",
      "        [  0, 302]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       360\n",
      "           1     1.0000    1.0000    1.0000       302\n",
      "\n",
      "    accuracy                         1.0000       662\n",
      "   macro avg     1.0000    1.0000    1.0000       662\n",
      "weighted avg     1.0000    1.0000    1.0000       662\n",
      "\n",
      "collision detection on the test set: \n",
      " tensor([[195,   4],\n",
      "        [  9,  94]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9799    0.9559    0.9677       204\n",
      "           1     0.9126    0.9592    0.9353        98\n",
      "\n",
      "    accuracy                         0.9570       302\n",
      "   macro avg     0.9463    0.9575    0.9515       302\n",
      "weighted avg     0.9581    0.9570    0.9572       302\n",
      "\n",
      "contact localization on the test set: \n",
      " tensor([[157,   4],\n",
      "        [  8, 133]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9752    0.9515    0.9632       165\n",
      "           1     0.9433    0.9708    0.9568       137\n",
      "\n",
      "    accuracy                         0.9603       302\n",
      "   macro avg     0.9592    0.9612    0.9600       302\n",
      "weighted avg     0.9607    0.9603    0.9603       302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the current working directory\n",
    "main_path = os.getcwd()\n",
    "num_features_lstm = 4\n",
    "'''\n",
    "#trained with all data\n",
    "contact_detection_path= main_path +'/trainedModels/contactDetection/trainedModel_06_30_2023_10:16:53.pth'\n",
    "collision_detection_path = main_path + '/trainedModels/collisionDetection/trainedModel_06_30_2023_09:07:24.pth'\n",
    "localization_path = main_path + '/trainedModels_without_torque/localization/trainedModel_06_30_2023_09:08:08.pth'\n",
    "'''\n",
    "# trained with training set\n",
    "contact_detection_path= main_path +'/trainedModels/contactDetection/trainedModel_01_24_2024_11:18:01.pth'\n",
    "collision_detection_path = main_path + '/trainedModels/collisionDetection/trainedModel_01_24_2024_11:12:30.pth'\n",
    "localization_path = main_path + '/trainedModels/localization/trainedModel_01_24_2024_11:15:06.pth'\n",
    "\n",
    "window_length = 28\n",
    "features_num = 28\n",
    "dof = 7\n",
    "\n",
    "# load model\n",
    "\n",
    "model_contact, labels_map_contact = import_lstm_models(PATH=contact_detection_path, num_features_lstm=num_features_lstm)\n",
    "model_collision, labels_map_collision = import_lstm_models(PATH=collision_detection_path, num_features_lstm=num_features_lstm)\n",
    "model_localization, labels_map_localization = import_lstm_models(PATH=localization_path, num_features_lstm=num_features_lstm)\n",
    "model_contact.double(); model_collision.double();model_localization.double()\n",
    "#contact detection labels--> 0:contact, 1: collision\n",
    "#contact localization labels--> 0:link5, 1:link6\n",
    "\n",
    "num_classes= 2\n",
    "confusionMatrix = ConfusionMatrix(task = \"multiclass\", num_classes= num_classes)\n",
    "\n",
    "with torch.no_grad():\n",
    "    collision= False; localization= False\n",
    "    training_data = create_tensor_dataset_without_torque(os.path.split(main_path)[0]+'/dataset/realData/contact_detection_train.csv',num_classes=num_classes, collision=collision, localization= localization, num_features_lstm=num_features_lstm)\n",
    "    testing_data = create_tensor_dataset_without_torque(os.path.split(main_path)[0]+'/dataset/realData/contact_detection_test.csv',num_classes=num_classes, collision=collision, localization= localization,num_features_lstm=num_features_lstm)\n",
    "    y_pred, y_test = get_output(testing_data, model_contact)\n",
    "    print(\"contact detection on the test set: \\n\",confusionMatrix(y_test , y_pred))\n",
    "    class_report_test = classification_report(y_test, y_pred,digits=4)\n",
    "    print(class_report_test)\n",
    "    # test on training set\n",
    "    #y_pred, y_train = get_output(training_data, model_contact)\n",
    "    #print(\"on the train set: \\n\",confusionMatrix(y_train , y_pred))\n",
    "   \n",
    "    collision= True; localization= False\n",
    "    training_data = create_tensor_dataset_without_torque(os.path.split(main_path)[0]+'/dataset/realData/contact_detection_train.csv',num_classes=num_classes, collision=collision, localization= localization, num_features_lstm=num_features_lstm)\n",
    "    testing_data = create_tensor_dataset_without_torque(os.path.split(main_path)[0]+'/dataset/realData/contact_detection_test.csv',num_classes=num_classes, collision=collision, localization= localization,num_features_lstm=num_features_lstm)\n",
    "    y_pred, y_test = get_output(testing_data, model_collision)\n",
    "    print(\"collision detection on the test set: \\n\",confusionMatrix(y_test , y_pred))\n",
    "    class_report_test = classification_report(y_test, y_pred,digits=4)\n",
    "    print(class_report_test)\n",
    "    # test on training set\n",
    "    #y_pred, y_train = get_output(training_data, model_collision)\n",
    "    #print(\"on the train set: \\n\",confusionMatrix(y_train , y_pred))\n",
    "    \n",
    "    collision= False; localization= True\n",
    "    training_data = create_tensor_dataset_without_torque(os.path.split(main_path)[0]+'/dataset/realData/contact_detection_train.csv',num_classes=num_classes, collision=collision, localization= localization, num_features_lstm=num_features_lstm)\n",
    "    testing_data = create_tensor_dataset_without_torque(os.path.split(main_path)[0]+'/dataset/realData/contact_detection_test.csv',num_classes=num_classes, collision=collision, localization= localization,num_features_lstm=num_features_lstm)\n",
    "    y_pred, y_test = get_output(testing_data, model_localization)\n",
    "    print(\"contact localization on the test set: \\n\",confusionMatrix(y_test , y_pred))\n",
    "    class_report_test = classification_report(y_test, y_pred,digits=4)\n",
    "    print(class_report_test)\n",
    "    # test on training set\n",
    "    #y_pred, y_train = get_output(training_data, model_localization)\n",
    "    #print(\"on the train set: \\n\",confusionMatrix(y_train , y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test modular design with 5 classes (similar to Mixed perception paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       360\n",
      "           1     0.9608    0.8596    0.9074       114\n",
      "           2     0.9072    0.9778    0.9412        90\n",
      "           3     0.8305    0.9608    0.8909        51\n",
      "           4     0.9773    0.9149    0.9451        47\n",
      "\n",
      "    accuracy                         0.9637       662\n",
      "   macro avg     0.9352    0.9426    0.9369       662\n",
      "weighted avg     0.9660    0.9637    0.9638       662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#contact detection labels--> 0:contact, 1: collision\n",
    "#contact localization labels--> 0:link5, 1:link6\n",
    "\n",
    "num_classes= 5\n",
    "collision=False; localization = False\n",
    "training_data = create_tensor_dataset_without_torque(os.path.split(main_path)[0]+'/dataset/realData/contact_detection_train.csv',num_classes=num_classes, collision=collision, localization= localization, num_features_lstm=num_features_lstm)\n",
    "testing_data = create_tensor_dataset_without_torque(os.path.split(main_path)[0]+'/dataset/realData/contact_detection_test.csv',num_classes=num_classes, collision=collision, localization= localization,num_features_lstm=num_features_lstm)\n",
    "\n",
    "confusionMatrix = ConfusionMatrix(task = \"multiclass\", num_classes= num_classes)\n",
    "\n",
    "model_contact.double(); model_collision.double();model_localization.double()\n",
    "\n",
    "y_test = testing_data.data_target\n",
    "y_pred = []\n",
    "for i in range(testing_data.data_target.shape[0]):\n",
    "    data_input = testing_data.__getitem__(i)[0].view(1,7,112)\n",
    "    model_out = model_contact(data_input)\n",
    "    #model_out = model_out.detach()\n",
    "    contact = torch.argmax(model_out, dim=1).numpy()[0]\n",
    "    if contact == 1:\n",
    "        model_out = model_collision(data_input)\n",
    "        model_out = model_out.detach()\n",
    "        collision = torch.argmax(model_out, dim=1).numpy()[0]\n",
    "\n",
    "        model_out = model_localization(data_input)\n",
    "        model_out = model_out.detach()\n",
    "        localization = torch.argmax(model_out, dim=1).numpy()[0]\n",
    "        if collision==0:\n",
    "            if localization ==0:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(2)\n",
    "        else:\n",
    "            if localization ==0:\n",
    "                y_pred.append(3)\n",
    "            else:\n",
    "                y_pred.append(4)\n",
    "            \n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "y_pred = torch.tensor(np.array(y_pred))\n",
    "y_test = np.array(y_test).astype('int64')\n",
    "class_report_test = classification_report(y_test, y_pred,digits=4)\n",
    "print(class_report_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test modular design with 3 classes (similar to DML paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       360\n",
      "           1     0.9799    0.9559    0.9677       204\n",
      "           2     0.9126    0.9592    0.9353        98\n",
      "\n",
      "    accuracy                         0.9804       662\n",
      "   macro avg     0.9642    0.9717    0.9677       662\n",
      "weighted avg     0.9809    0.9804    0.9805       662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#contact detection labels--> 0:contact, 1: collision\n",
    "#contact localization labels--> 0:link5, 1:link6\n",
    "\n",
    "num_classes= 3\n",
    "collision=False; localization = False\n",
    "training_data = create_tensor_dataset_without_torque(os.path.split(main_path)[0]+'/dataset/realData/contact_detection_train.csv',num_classes=num_classes, collision=collision, localization= localization, num_features_lstm=num_features_lstm)\n",
    "testing_data = create_tensor_dataset_without_torque(os.path.split(main_path)[0]+'/dataset/realData/contact_detection_test.csv',num_classes=num_classes, collision=collision, localization= localization,num_features_lstm=num_features_lstm)\n",
    "\n",
    "confusionMatrix = ConfusionMatrix(task = \"multiclass\", num_classes= num_classes)\n",
    "\n",
    "model_contact.double(); model_collision.double();model_localization.double()\n",
    "\n",
    "y_test = testing_data.data_target\n",
    "y_pred = []\n",
    "for i in range(testing_data.data_target.shape[0]):\n",
    "    data_input = testing_data.__getitem__(i)[0].view(1,7,112)\n",
    "    model_out = model_contact(data_input)\n",
    "    #model_out = model_out.detach()\n",
    "    contact = torch.argmax(model_out, dim=1).numpy()[0]\n",
    "    if contact == 1:\n",
    "        model_out = model_collision(data_input)\n",
    "        model_out = model_out.detach()\n",
    "        collision = torch.argmax(model_out, dim=1).numpy()[0]\n",
    "\n",
    "        model_out = model_localization(data_input)\n",
    "        model_out = model_out.detach()\n",
    "        localization = torch.argmax(model_out, dim=1).numpy()[0]\n",
    "        if collision==0:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(2)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "y_pred = torch.tensor(np.array(y_pred))\n",
    "y_test = np.array(y_test).astype('int64')\n",
    "class_report_test = classification_report(y_test, y_pred,digits=4)\n",
    "print(class_report_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test model with 5 classes (similar to mixed_perception paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***  Models loaded  ***\n",
      "on the test set: \n",
      " tensor([[360,   2,   0,   0,   0],\n",
      "        [  0,  85,   2,   0,   0],\n",
      "        [  0,  14,  86,   2,   2],\n",
      "        [  0,  10,   0,  49,   1],\n",
      "        [  0,   3,   2,   0,  44]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9945    1.0000    0.9972       360\n",
      "           1     0.9770    0.7456    0.8458       114\n",
      "           2     0.8269    0.9556    0.8866        90\n",
      "           3     0.8167    0.9608    0.8829        51\n",
      "           4     0.8980    0.9362    0.9167        47\n",
      "\n",
      "    accuracy                         0.9426       662\n",
      "   macro avg     0.9026    0.9196    0.9058       662\n",
      "weighted avg     0.9481    0.9426    0.9416       662\n",
      "\n",
      "on the train set: \n",
      " tensor([[839,   0,   0,   0,   0],\n",
      "        [  0, 202,   0,   0,   0],\n",
      "        [  0,  17, 217,   0,   0],\n",
      "        [  0,   5,   0, 129,   0],\n",
      "        [  0,   1,   1,   0, 132]])\n"
     ]
    }
   ],
   "source": [
    "def import_models(PATH, num_class=5, network_type = 'main'):\n",
    "\n",
    "\tmodel = Sequence(num_class, network_type= network_type )\n",
    "\tcheckpoint = torch.load(PATH)\n",
    "\tmodel.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\tmodel.eval()\n",
    "\tprint('***  Models loaded  ***')\n",
    "\treturn model.eval()\n",
    "\n",
    "network_type = 'main'\n",
    "num_classes= 5; collision= False; localization= False\n",
    "model_collision.double()\n",
    "training_data = create_tensor_dataset_without_torque(os.path.split(main_path)[0]+'/dataset/realData/contact_detection_train.csv',num_classes=num_classes, collision=collision, localization= localization, num_features_lstm=num_features_lstm)\n",
    "testing_data = create_tensor_dataset_without_torque(os.path.split(main_path)[0]+'/dataset/realData/contact_detection_test.csv',num_classes=num_classes, collision=collision, localization= localization,num_features_lstm=num_features_lstm)\n",
    "\n",
    "model = import_models(os.path.split(main_path)[0]+'/AIModels/trainedModels/monolithicModels/trainedModel_05_17_2023_14:57:38.pth', num_class= num_classes, network_type= network_type) \n",
    "\n",
    "model.double()\n",
    "with torch.no_grad():\n",
    "\tconfusionMatrix = ConfusionMatrix(task = \"multiclass\", num_classes= num_classes)\n",
    "\n",
    "\ty_pred, y_test = get_output(testing_data, model)\n",
    "\tprint(\"on the test set: \\n\",confusionMatrix(y_test , y_pred))\n",
    "\n",
    "\n",
    "\tclass_report_test = classification_report(y_test, y_pred,digits=4)\n",
    "\tprint(class_report_test)\n",
    "\n",
    "\ty_pred, y_train = get_output(training_data, model)\n",
    "\tprint(\"on the train set: \\n\",confusionMatrix(y_train , y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test model with 5 classes (similar to DML paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***  Models loaded  ***\n",
      "on the test set: \n",
      " tensor([[360,   0,   0],\n",
      "        [  0, 193,   9],\n",
      "        [  0,  11,  89]])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       360\n",
      "           1     0.9554    0.9461    0.9507       204\n",
      "           2     0.8900    0.9082    0.8990        98\n",
      "\n",
      "    accuracy                         0.9698       662\n",
      "   macro avg     0.9485    0.9514    0.9499       662\n",
      "weighted avg     0.9700    0.9698    0.9699       662\n",
      "\n",
      "on the train set: \n",
      " tensor([[839,   0,   0],\n",
      "        [  0, 441,   0],\n",
      "        [  0,   2, 261]])\n"
     ]
    }
   ],
   "source": [
    "def import_models(PATH, num_class=5, network_type = 'main'):\n",
    "\n",
    "\tmodel = Sequence(num_class, network_type= network_type )\n",
    "\tcheckpoint = torch.load(PATH)\n",
    "\tmodel.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\tmodel.eval()\n",
    "\tprint('***  Models loaded  ***')\n",
    "\treturn model.eval()\n",
    "\n",
    "network_type = 'main'\n",
    "num_classes= 3; collision= False; localization= False\n",
    "model_collision.double()\n",
    "training_data = create_tensor_dataset_without_torque(os.path.split(main_path)[0]+'/dataset/realData/contact_detection_train.csv',num_classes=num_classes, collision=collision, localization= localization, num_features_lstm=num_features_lstm)\n",
    "testing_data = create_tensor_dataset_without_torque(os.path.split(main_path)[0]+'/dataset/realData/contact_detection_test.csv',num_classes=num_classes, collision=collision, localization= localization,num_features_lstm=num_features_lstm)\n",
    "\n",
    "model = import_models(os.path.split(main_path)[0]+'/AIModels/trainedModels/monolithicModels/trainedModel_05_20_2023_12:39:22.pth', num_class= num_classes, network_type= network_type) \n",
    "\n",
    "model.double()\n",
    "with torch.no_grad():\n",
    "\tconfusionMatrix = ConfusionMatrix(task = \"multiclass\", num_classes= num_classes)\n",
    "\n",
    "\ty_pred, y_test = get_output(testing_data, model)\n",
    "\tprint(\"on the test set: \\n\",confusionMatrix(y_test , y_pred))\n",
    "\n",
    "\tclass_report_test = classification_report(y_test, y_pred, digits=4)\n",
    "\tprint(class_report_test)\n",
    "\n",
    "\ty_pred, y_train = get_output(training_data, model)\n",
    "\tprint(\"on the train set: \\n\",confusionMatrix(y_train , y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class           Precision       Recall          F1-Score       \n",
      "------------------------------------------------------------\n",
      "Class 0         1.0000          1.0000          1.0000         \n",
      "Class 1         0.9808          0.9623          0.9714         \n",
      "Class 2         0.9588          0.9789          0.9687         \n",
      "\n",
      "Weighted-average:\n",
      "Metric          Score                          \n",
      "------------------------------\n",
      "Precision       0.9861                         \n",
      "Recall          0.9860                         \n",
      "F1-Score        0.9860                         \n",
      "\n",
      "Macro-average:\n",
      "Metric          Score                          \n",
      "------------------------------\n",
      "Precision       0.9798                         \n",
      "Recall          0.9804                         \n",
      "F1-Score        0.9801                         \n"
     ]
    }
   ],
   "source": [
    "def classification_report_from_confusion_matrix(confusion_matrix):\n",
    "    TP = confusion_matrix.diag()\n",
    "    FP = confusion_matrix.sum(dim=0) - TP\n",
    "    FN = confusion_matrix.sum(dim=1) - TP\n",
    "\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    class_report = {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1-score\": f1,\n",
    "        \"support\": TP + FN\n",
    "    }\n",
    "\n",
    "    return class_report\n",
    "\n",
    "\n",
    "confusion_matrix= torch.tensor([[228, 0, 0],\n",
    "                              [0, 102, 4],\n",
    "                              [0, 2, 93],])\n",
    "\n",
    "# Calculate class-wise metrics\n",
    "class_report = classification_report_from_confusion_matrix(confusion_matrix)\n",
    "\n",
    "# Print the formatted report\n",
    "print(\"{:<15} {:<15} {:<15} {:<15}\".format(\"Class\", \"Precision\", \"Recall\", \"F1-Score\"))\n",
    "print(\"-\" * 60)\n",
    "for i, (precision, recall, f1, support) in enumerate(zip(class_report[\"precision\"], class_report[\"recall\"], class_report[\"f1-score\"], class_report[\"support\"])):\n",
    "    print(\"{:<15} {:<15.4f} {:<15.4f} {:<15.4f}\".format(f\"Class {i}\", precision.item(), recall.item(), f1.item()))\n",
    "\n",
    "# weighted-average\n",
    "class_counts = np.sum(np.array(confusion_matrix), axis=1)\n",
    "# Calculate weighted average precision\n",
    "weights = class_counts / float(sum(class_counts))\n",
    "micro_precision = np.sum(np.array(class_report['precision']) * weights)\n",
    "micro_recall = np.sum(np.array(class_report['recall']) * weights)\n",
    "micro_f1 = np.sum(np.array(class_report['f1-score']) * weights)\n",
    "\n",
    "print(\"\\nWeighted-average:\")\n",
    "print(\"{:<15} {:<15} {:<15}\".format(\"Metric\", \"Score\", \"\"))\n",
    "print(\"-\" * 30)\n",
    "print(\"{:<15} {:<15.4f} {:<15}\".format(\"Precision\", micro_precision, \"\"))\n",
    "print(\"{:<15} {:<15.4f} {:<15}\".format(\"Recall\", micro_recall, \"\"))\n",
    "print(\"{:<15} {:<15.4f} {:<15}\".format(\"F1-Score\", micro_f1, \"\"))\n",
    "\n",
    "\n",
    "# Calculate macro-average metrics\n",
    "macro_precision = class_report[\"precision\"].mean().item()\n",
    "macro_recall = class_report[\"recall\"].mean().item()\n",
    "macro_f1 = class_report[\"f1-score\"].mean().item()\n",
    "\n",
    "# Print macro-average metrics\n",
    "print(\"\\nMacro-average:\")\n",
    "print(\"{:<15} {:<15} {:<15}\".format(\"Metric\", \"Score\", \"\"))\n",
    "print(\"-\" * 30)\n",
    "print(\"{:<15} {:<15.4f} {:<15}\".format(\"Precision\", macro_precision, \"\"))\n",
    "print(\"{:<15} {:<15.4f} {:<15}\".format(\"Recall\", macro_recall, \"\"))\n",
    "print(\"{:<15} {:<15.4f} {:<15}\".format(\"F1-Score\", macro_f1, \"\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class           Precision       Recall          F1-Score       \n",
      "------------------------------------------------------------\n",
      "Class 0         1.0000          0.9837          0.9918         \n",
      "Class 1         0.9118          0.9118          0.9118         \n",
      "Class 2         0.9022          0.9651          0.9326         \n",
      "Class 3         0.9259          0.8929          0.9091         \n",
      "Class 4         0.9630          0.9630          0.9630         \n",
      "\n",
      "Weighted-average:\n",
      "Metric          Score                          \n",
      "------------------------------\n",
      "Precision       0.9567                         \n",
      "Recall          0.9559                         \n",
      "F1-Score        0.9561                         \n",
      "\n",
      "Macro-average:\n",
      "Metric          Score                          \n",
      "------------------------------\n",
      "Precision       0.9406                         \n",
      "Recall          0.9433                         \n",
      "F1-Score        0.9416                         \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def classification_report_from_confusion_matrix(confusion_matrix):\n",
    "    TP = confusion_matrix.diag()\n",
    "    FP = confusion_matrix.sum(dim=0) - TP\n",
    "    FN = confusion_matrix.sum(dim=1) - TP\n",
    "\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    class_report = {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1-score\": f1,\n",
    "        \"support\": TP + FN\n",
    "    }\n",
    "\n",
    "    return class_report\n",
    "\n",
    "# Your confusion matrix\n",
    "confusion_matrix = torch.tensor([[242, 0, 3, 0, 1],\n",
    "                               [0, 93, 4, 4, 1],\n",
    "                               [0, 3, 83, 0, 0],\n",
    "                               [0, 6, 0, 50, 0],\n",
    "                               [0, 0, 2, 0, 52]])\n",
    "\n",
    "# Calculate class-wise metrics\n",
    "class_report = classification_report_from_confusion_matrix(confusion_matrix)\n",
    "\n",
    "# Print class-wise metrics\n",
    "print(\"{:<15} {:<15} {:<15} {:<15}\".format(\"Class\", \"Precision\", \"Recall\", \"F1-Score\"))\n",
    "print(\"-\" * 60)\n",
    "for i, (precision, recall, f1, support) in enumerate(zip(class_report[\"precision\"], class_report[\"recall\"], class_report[\"f1-score\"], class_report[\"support\"])):\n",
    "    print(\"{:<15} {:<15.4f} {:<15.4f} {:<15.4f}\".format(f\"Class {i}\", precision.item(), recall.item(), f1.item()))\n",
    "\n",
    "# Calculate macro-average metrics\n",
    "macro_precision = class_report[\"precision\"].mean().item()\n",
    "macro_recall = class_report[\"recall\"].mean().item()\n",
    "macro_f1 = class_report[\"f1-score\"].mean().item()\n",
    "\n",
    "# weighted-average\n",
    "class_counts = np.sum(np.array(confusion_matrix), axis=1)\n",
    "# Calculate weighted average precision\n",
    "weights = class_counts / float(sum(class_counts))\n",
    "micro_precision = np.sum(np.array(class_report['precision']) * weights)\n",
    "micro_recall = np.sum(np.array(class_report['recall']) * weights)\n",
    "micro_f1 = np.sum(np.array(class_report['f1-score']) * weights)\n",
    "\n",
    "\n",
    "print(\"\\nWeighted-average:\")\n",
    "print(\"{:<15} {:<15} {:<15}\".format(\"Metric\", \"Score\", \"\"))\n",
    "print(\"-\" * 30)\n",
    "print(\"{:<15} {:<15.4f} {:<15}\".format(\"Precision\", micro_precision, \"\"))\n",
    "print(\"{:<15} {:<15.4f} {:<15}\".format(\"Recall\", micro_recall, \"\"))\n",
    "print(\"{:<15} {:<15.4f} {:<15}\".format(\"F1-Score\", micro_f1, \"\"))\n",
    "\n",
    "# Print macro-average metrics\n",
    "print(\"\\nMacro-average:\")\n",
    "print(\"{:<15} {:<15} {:<15}\".format(\"Metric\", \"Score\", \"\"))\n",
    "print(\"-\" * 30)\n",
    "print(\"{:<15} {:<15.4f} {:<15}\".format(\"Precision\", macro_precision, \"\"))\n",
    "print(\"{:<15} {:<15.4f} {:<15}\".format(\"Recall\", macro_recall, \"\"))\n",
    "print(\"{:<15} {:<15.4f} {:<15}\".format(\"F1-Score\", macro_f1, \"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
